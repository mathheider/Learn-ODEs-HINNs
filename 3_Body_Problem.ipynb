{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-Body Problem",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb_RbZIQtT3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99908d4-8939-4d7a-e51e-42d856f12c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default data type: torch.float64\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from scipy.integrate import solve_ivp\n",
        "#!pip install tikzplotlib #uncomment for saving nice images\n",
        "#import tikzplotlib\n",
        "# set precision\n",
        "torch.set_default_dtype(torch.float64)\n",
        "print('Default data type:', torch.get_default_dtype())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch, pickle, zipfile, sys\n",
        "import imageio, shutil\n",
        "import scipy, scipy.misc, scipy.integrate\n",
        "solve_ivp = scipy.integrate.solve_ivp\n",
        "\n"
      ],
      "metadata": {
        "id": "lN6WkMOZ3ZzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hessquik\n",
        "import hessQuik.activations as act\n",
        "import hessQuik.layers as lay\n",
        "import hessQuik.networks as net\n",
        "from hessQuik.utils import  test"
      ],
      "metadata": {
        "id": "LEbej7jguKLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d669f1-4f12-4958-8e11-7f2c8f3c589a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hessquik in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from hessquik) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->hessquik) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data set from !!!\n",
        "# Hamiltonian Neural Networks | 2019\n",
        "# Sam Greydanus, Misko Dzamba, Jason Yosinski\n",
        "#https://github.com/greydanus/hamiltonian-nn/blob/master/experiment-3body/data.py\n",
        "\n",
        "def to_pickle(thing, path): # save something\n",
        "    with open(path, 'wb') as handle:\n",
        "        pickle.dump(thing, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "def from_pickle(path): # load something\n",
        "    thing = None\n",
        "    with open(path, 'rb') as handle:\n",
        "        thing = pickle.load(handle)\n",
        "    return thing\n",
        "\n",
        "##### ENERGY #####\n",
        "def potential_energy(state):\n",
        "    '''U=\\sum_i,j>i G m_i m_j / r_ij'''\n",
        "    tot_energy = np.zeros((1,1,state.shape[2]))\n",
        "    for i in range(state.shape[0]):\n",
        "        for j in range(i+1,state.shape[0]):\n",
        "            r_ij = ((state[i:i+1,1:3] - state[j:j+1,1:3])**2).sum(1, keepdims=True)**.5\n",
        "            m_i = state[i:i+1,0:1]\n",
        "            m_j = state[j:j+1,0:1]\n",
        "            tot_energy += m_i * m_j / r_ij\n",
        "    U = -tot_energy.sum(0).squeeze()\n",
        "    return U\n",
        "\n",
        "def kinetic_energy(state):\n",
        "    '''T=\\sum_i .5*m*v^2'''\n",
        "    energies = .5 * state[:,0:1] * (state[:,3:5]**2).sum(1, keepdims=True)\n",
        "    T = energies.sum(0).squeeze()\n",
        "    return T\n",
        "\n",
        "def total_energy(state):\n",
        "    return potential_energy(state) + kinetic_energy(state)\n",
        "\n",
        "\n",
        "##### DYNAMICS #####\n",
        "def get_accelerations(state, epsilon=0):\n",
        "    # shape of state is [bodies x properties]\n",
        "    net_accs = [] # [nbodies x 2]\n",
        "    for i in range(state.shape[0]): # number of bodies\n",
        "        other_bodies = np.concatenate([state[:i, :], state[i+1:, :]], axis=0)\n",
        "        displacements = other_bodies[:, 1:3] - state[i, 1:3] # indexes 1:3 -> pxs, pys\n",
        "        distances = (displacements**2).sum(1, keepdims=True)**0.5\n",
        "        masses = other_bodies[:, 0:1] # index 0 -> mass\n",
        "        pointwise_accs = masses * displacements / (distances**3 + epsilon) # G=1\n",
        "        net_acc = pointwise_accs.sum(0, keepdims=True)\n",
        "        net_accs.append(net_acc)\n",
        "    net_accs = np.concatenate(net_accs, axis=0)\n",
        "    return net_accs\n",
        "  \n",
        "def update(t, state):\n",
        "    state = state.reshape(-1,5) # [bodies, properties]\n",
        "    deriv = np.zeros_like(state)\n",
        "    deriv[:,1:3] = state[:,3:5] # dx, dy = vx, vy\n",
        "    deriv[:,3:5] = get_accelerations(state)\n",
        "    return deriv.reshape(-1)\n",
        "\n",
        "\n",
        "##### INTEGRATION SETTINGS #####\n",
        "def get_orbit(state, update_fn=update, t_points=100, t_span=[0,2], nbodies=3, **kwargs):\n",
        "    if not 'rtol' in kwargs.keys():\n",
        "        kwargs['rtol'] = 1e-9\n",
        "\n",
        "    orbit_settings = locals()\n",
        "\n",
        "    nbodies = state.shape[0]\n",
        "    t_eval = np.linspace(t_span[0], t_span[1], t_points)\n",
        "    orbit_settings['t_eval'] = t_eval\n",
        "\n",
        "    path = solve_ivp(fun=update_fn, t_span=t_span, y0=state.flatten(),\n",
        "                     t_eval=t_eval, **kwargs)\n",
        "    orbit = path['y'].reshape(nbodies, 5, t_points)\n",
        "    return orbit, orbit_settings\n",
        "\n",
        "\n",
        "##### INITIALIZE THE TWO BODIES #####\n",
        "def rotate2d(p, theta):\n",
        "  c, s = np.cos(theta), np.sin(theta)\n",
        "  R = np.array([[c, -s],[s, c]])\n",
        "  return (R @ p.reshape(2,1)).squeeze()\n",
        "\n",
        "def random_config(nu=2e-1, min_radius=0.9, max_radius=1.2):\n",
        "  '''This is not principled at all yet'''\n",
        "  state = np.zeros((3,5))\n",
        "  state[:,0] = 1\n",
        "  p1 = 2*np.random.rand(2) - 1\n",
        "  r = np.random.rand() * (max_radius-min_radius) + min_radius\n",
        "  \n",
        "  p1 *= r/np.sqrt( np.sum((p1**2)) )\n",
        "  p2 = rotate2d(p1, theta=2*np.pi/3)\n",
        "  p3 = rotate2d(p2, theta=2*np.pi/3)\n",
        "\n",
        "  # # velocity that yields a circular orbit\n",
        "  v1 = rotate2d(p1, theta=np.pi/2)\n",
        "  v1 = v1 / r**1.5\n",
        "  v1 = v1 * np.sqrt(np.sin(np.pi/3)/(2*np.cos(np.pi/6)**2)) # scale factor to get circular trajectories\n",
        "  v2 = rotate2d(v1, theta=2*np.pi/3)\n",
        "  v3 = rotate2d(v2, theta=2*np.pi/3)\n",
        "  \n",
        "  # make the circular orbits slightly chaotic\n",
        "  v1 *= 1 + nu*(2*np.random.rand(2) - 1)\n",
        "  v2 *= 1 + nu*(2*np.random.rand(2) - 1)\n",
        "  v3 *= 1 + nu*(2*np.random.rand(2) - 1)\n",
        "\n",
        "  state[0,1:3], state[0,3:5] = p1, v1\n",
        "  state[1,1:3], state[1,3:5] = p2, v2\n",
        "  state[2,1:3], state[2,3:5] = p3, v3\n",
        "  return state\n",
        "\n",
        "\n",
        "##### INTEGRATE AN ORBIT OR TWO #####\n",
        "def sample_orbits(timesteps=20, trials=5000, nbodies=3, orbit_noise=2e-1,\n",
        "                  min_radius=0.9, max_radius=1.2, t_span=[0, 5], verbose=False, **kwargs):\n",
        "    \n",
        "    orbit_settings = locals()\n",
        "    if verbose:\n",
        "        print(\"Making a dataset of near-circular 3-body orbits:\")\n",
        "    \n",
        "    x, dx, e = [], [], []\n",
        "    N = timesteps*trials\n",
        "    while len(x) < N:\n",
        "\n",
        "        state = random_config(nu=orbit_noise, min_radius=min_radius, max_radius=max_radius)\n",
        "        orbit, settings = get_orbit(state, t_points=timesteps, t_span=t_span, nbodies=nbodies, **kwargs)\n",
        "        batch = orbit.transpose(2,0,1).reshape(-1,nbodies*5)\n",
        "\n",
        "        for state in batch:\n",
        "            dstate = update(None, state)\n",
        "            \n",
        "            # reshape from [nbodies, state] where state=[m, qx, qy, px, py]\n",
        "            # to [canonical_coords] = [qx1, qx2, qy1, qy2, px1,px2,....]\n",
        "            coords = state.reshape(nbodies,5).T[1:].flatten()\n",
        "            dcoords = dstate.reshape(nbodies,5).T[1:].flatten()\n",
        "            x.append(coords)\n",
        "            dx.append(dcoords)\n",
        "\n",
        "            shaped_state = state.copy().reshape(nbodies,5,1)\n",
        "            e.append(total_energy(shaped_state))\n",
        "\n",
        "    data = {'coords': np.stack(x)[:N],\n",
        "            'dcoords': np.stack(dx)[:N],\n",
        "            'energy': np.stack(e)[:N] }\n",
        "    return data, orbit_settings\n",
        "\n",
        "\n",
        "##### MAKE A DATASET #####\n",
        "def make_orbits_dataset(test_split=0.2, **kwargs):\n",
        "    data, orbit_settings = sample_orbits(**kwargs)\n",
        "    \n",
        "    # make a train/test split\n",
        "    split_ix = int(data['coords'].shape[0] * test_split)\n",
        "    split_data = {}\n",
        "    for k, v in data.items():\n",
        "        split_data[k], split_data['test_' + k] = v[split_ix:], v[:split_ix]\n",
        "    data = split_data\n",
        "\n",
        "    data['meta'] = orbit_settings\n",
        "    return data\n",
        "\n",
        "\n",
        "##### LOAD OR SAVE THE DATASET #####\n",
        "def get_dataset(experiment_name, save_dir, **kwargs):\n",
        "    '''Returns an orbital dataset. Also constructs\n",
        "    the dataset if no saved version is available.'''\n",
        "\n",
        "    path = '{}/{}-orbits-dataset.pkl'.format(save_dir, experiment_name)\n",
        "\n",
        "    try:\n",
        "        data = from_pickle(path)\n",
        "        print(\"Successfully loaded data from {}\".format(path))\n",
        "    except:\n",
        "        print(\"Had a problem loading data from {}. Rebuilding dataset...\".format(path))\n",
        "        data = make_orbits_dataset(**kwargs)\n",
        "        to_pickle(data, path)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "XNHlK2_c3cL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qzUkvDgXqSD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = 2000      # number of training points\n",
        "n_val = 300         # number of validation points\n",
        "n_test = 300        # number of testing points\n",
        "#import data and assign each array to a different value\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "data = get_dataset(\"3BodyData\", \"\", verbose=True)\n",
        "\n",
        "timesteps = []\n",
        "for x in range(80000):\n",
        "  timesteps += [x]\n",
        "data[\"timestep\"] = timesteps \n",
        "del data[\"dcoords\"]\n",
        "del data[\"test_dcoords\"]\n",
        "del data[\"test_energy\"]\n",
        "del data[\"meta\"]\n",
        "del data[\"test_coords\"]\n",
        "\n",
        "\n",
        "#data goes qx1 qx2 qx3, qy1 qy2 qy3, px1 px2 px3, py1 py2 py3 we think\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8-aPwHzUXRA",
        "outputId": "4e03db54-2a88-49da-e098-b7fe9710b571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Had a problem loading data from /3BodyData-orbits-dataset.pkl. Rebuilding dataset...\n",
            "Making a dataset of near-circular 3-body orbits:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "px1 = []\n",
        "px2 = []\n",
        "px3 = []\n",
        "qx1 = []\n",
        "qx2 = []\n",
        "qx3 = []\n",
        "py1 = []\n",
        "py2 = []\n",
        "py3 = []\n",
        "qy1 = []\n",
        "qy2 = []\n",
        "qy3 = []\n",
        "for x in data[\"coords\"]:\n",
        "  for y in range(len(x)):\n",
        "    if y % 12 == 0:\n",
        "      px1 += [x[y]]\n",
        "    elif y % 12 == 1:\n",
        "      px2 += [x[y]]\n",
        "    elif y % 12 == 2:\n",
        "      px3 += [x[y]]\n",
        "    elif y % 12 == 3:\n",
        "      py1 += [x[y]]\n",
        "    elif y % 12 == 4:\n",
        "      py2 += [x[y]]\n",
        "    elif y % 12 == 5:\n",
        "      py3 += [x[y]]\n",
        "    elif y % 12 == 6:\n",
        "      qx1 += [x[y]]\n",
        "    elif y % 12 == 7:\n",
        "      qx2 += [x[y]]\n",
        "    elif y % 12 == 8:\n",
        "      qx3 += [x[y]]\n",
        "    elif y % 12 == 9:\n",
        "      qy1 += [x[y]]\n",
        "    elif y % 12 == 10:\n",
        "      qy2 += [x[y]]\n",
        "    elif y % 12 == 11:\n",
        "      qy3 += [x[y]]\n",
        "    \n"
      ],
      "metadata": {
        "id": "FARULazQwBtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(qx2))\n",
        "for x in range(3):\n",
        "  print(px1[x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWdh1TjiEVyo",
        "outputId": "7e5c3a11-ce06-4eac-c050-a2b3eb4f9ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80000\n",
            "0.7781306889871661\n",
            "0.9235967237073314\n",
            "1.0412723488583533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#these are the tensors of our data\n",
        "px1Data =  np.reshape(px1,[-1,1])\n",
        "\n",
        "px2Data =  np.reshape(px2,[-1,1])\n",
        "px3Data =  np.reshape(px3,[-1,1])\n",
        "qx1Data =  np.reshape(qx1,[-1,1])\n",
        "qx2Data =  np.reshape(qx2,[-1,1])\n",
        "qx3Data =   np.reshape(qx3,[-1,1])\n",
        "py1Data =  np.reshape(py1,[-1,1]) \n",
        "py2Data =  np.reshape(py2,[-1,1])\n",
        "py3Data =  np.reshape(py3,[-1,1])\n",
        "qy1Data =  np.reshape(qy1,[-1,1])\n",
        "qy2Data =   np.reshape(qy2,[-1,1])\n",
        "qy3Data =  np.reshape(qy3,[-1,1])\n",
        "timeStep = np.reshape(data[\"timestep\"],[-1,1])\n",
        "# assign data to x and y\n",
        "\n",
        "x = np.concatenate([timeStep,px1Data,px2Data,px3Data,py1Data,py2Data,py3Data,qx1Data,qx2Data,qx3Data,qy1Data,qy2Data,qy3Data],axis=1) #combine the y and z data \n",
        "x = torch.tensor(x)\n",
        "y = np.concatenate([px1Data,px2Data,px3Data,py1Data,py2Data,py3Data,qx1Data,qx2Data,qx3Data,qy1Data,qy2Data,qy3Data],axis =1 )\n",
        "y = torch.tensor(y)\n",
        "\n",
        "# no shuffling\n",
        "n_samples = n_train\n",
        "x_train, y_train = x[:n_train], y[1:n_train+1]\n",
        "x_val, y_val = x_train[3:17], y_train[3:17]\n",
        "x_test, y_test = x_train[7:28], y_train[7:28]\n",
        "\n",
        "print(x_train.size())\n",
        "print(y_train.size())\n",
        "# shuffle and split data\n",
        "# idx = torch.randperm(n_train + n_val + n_test)\n",
        "# x_train, y_train = x[idx[:n_train]], y[idx[:n_train]]\n",
        "# x_val, y_val = x[idx[n_train:n_train + n_val]], y[idx[n_train:n_train + n_val]]\n",
        "# x_test, y_test = x[idx[n_train + n_val:]], y[idx[n_train + n_val:]]\n",
        "\n",
        "stepSize = (x_train[1,0] - x_train[0,0])\n",
        "print(\"stepsize=\", stepSize)"
      ],
      "metadata": {
        "id": "i8s646yI5Pv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc2fa47-50a8-4021-c561-14eaf286da40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2000, 13])\n",
            "torch.Size([2000, 12])\n",
            "stepsize= tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "width = 20\n",
        "depth = 3\n",
        "f = net.NN(lay.singleLayer(13, width, act=act.tanhActivation()),\n",
        "           net.resnetNN(width, depth, h=0.5, act=act.tanhActivation()),\n",
        "           lay.singleLayer(width, 1, act=act.identityActivation()))\n",
        "#print(f)\n",
        "# Pytorch optimizer for the network weights\n",
        "optimizer = torch.optim.Adam(f.parameters(), lr=1e-3) #weight decay is for regularization weight_decay=1e-5 add this for regularization\n"
      ],
      "metadata": {
        "id": "o9hAlQosuNd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse_loss(y_true: torch.Tensor,y: torch.Tensor):\n",
        "  return (0.5 / y.shape[0]) * torch.norm(y_true - y.view_as(y_true)) ** 2"
      ],
      "metadata": {
        "id": "ngOGu5CuuaJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_headers( verbose: bool = True):\n",
        "    r\"\"\"\n",
        "    Print headers for nice training\n",
        "    \"\"\"\n",
        "    loss_printouts = ('loss',)\n",
        "    n_loss = len(loss_printouts)\n",
        "\n",
        "    headers = (('', '', '|', 'running',) + (n_loss - 1) * ('',) + ('|', 'train',)\n",
        "               + (n_loss - 1) * ('',) + ('|', 'valid',) + (n_loss - 1) * ('',))\n",
        "\n",
        "    printouts = ('epoch', 'time') + 3 * (('|',) + loss_printouts)\n",
        "    printouts_frmt = '{:<15d}{:<15.4f}' + 3 * ('{:<2s}' + n_loss * '{:<15.4e}')\n",
        "\n",
        "    if verbose:\n",
        "        print(('{:<15s}{:<15s}' + 3 * ('{:<2s}' + n_loss * '{:<15s}')).format(*headers))\n",
        "        print(('{:<15s}{:<15s}' + 3 * ('{:<2s}' + n_loss * '{:<15s}')).format(*printouts))\n",
        "\n",
        "    return headers, printouts, printouts_frmt"
      ],
      "metadata": {
        "id": "qDNvY0D9uZ_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training parameters\n",
        "max_epochs = 1000\n",
        "batch_size = n_samples\n",
        "\n",
        "# get printouts\n",
        "headers, printouts_str, printouts_frmt = print_headers()\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# initial evaluation\n",
        "f_train = f(x_train,do_gradient=True,do_hessian = False) \n",
        "#now construct the neural nets for validation\n",
        "\n",
        "f_val = f(x_val,do_gradient=True,do_hessian = False)\n",
        "#loss_val = mse_loss(torch.cat((yTimeOneVal,zTimeOneVal),dim=1),y_val)\n",
        "fpx1 = ((f_train[1])[:,1,:]) #The y data from our net\n",
        "fpx2 = ((f_train[1])[:,2,:]) #the z data from our net\n",
        "fpx3 = ((f_train[1])[:,3,:]) #The y data from our net\n",
        "fpy1 = ((f_train[1])[:,4,:]) #the z data from our net\n",
        "fpy2 = ((f_train[1])[:,5,:]) #The y data from our net\n",
        "fpy3 = ((f_train[1])[:,6,:]) #the z data from our net\n",
        "fqx1 = ((f_train[1])[:,7,:]) #The y data from our net\n",
        "fqx2 = ((f_train[1])[:,8,:]) #the z data from our net\n",
        "fqx3 = ((f_train[1])[:,9,:]) #The y data from our net\n",
        "fqy1 = ((f_train[1])[:,10,:]) #the z data from our net\n",
        "fqy2 = ((f_train[1])[:,11,:]) #The y data from our net\n",
        "fqy3 = ((f_train[1])[:,12,:]) #the z data from our net\n",
        "\n",
        "px1TimeOneVal = 1 * stepSize*fqx1  + x_train[:,1:2]\n",
        "px2TimeOneVal = 1 * stepSize*fqx2 + x_train[:,2:3]\n",
        "px3TimeOneVal = 1 *stepSize*fqx3  + x_train[:,3:4]\n",
        "py1TimeOneVal = 1 * stepSize*fqy1 + x_train[:,4:5]\n",
        "py2TimeOneVal = 1 * stepSize*fqy2  + x_train[:,5:6]\n",
        "py3TimeOneVal = 1 * stepSize*fqy3 + x_train[:,6:7]\n",
        "qx1TimeOneVal = -1 * stepSize*fpx1  + x_train[:,7:8]\n",
        "qx2TimeOneVal = -1 * stepSize*fpx2 + x_train[:,8:9]\n",
        "qx3TimeOneVal = -1 * stepSize*fpx3  + x_train[:,9:10]\n",
        "qy1TimeOneVal = -1 * stepSize*fpy1 + x_train[:,10:11]\n",
        "qy2TimeOneVal = -1 * stepSize*fpy2  + x_train[:,11:12]\n",
        "qy3TimeOneVal = -1 * stepSize*fpy3 + x_train[:,12:13]\n",
        "\n",
        "#For printing: \n",
        "\n",
        "his_iter = (-1, 0.0) + ('|',) + (0,) + ('|',) + (0,) + ('|',) + (0,)\n",
        "# print(printouts_frmt.format(*his_iter))\n",
        "\n",
        "# store history\n",
        "his = np.array([x for x in his_iter if not (x == '|')]).reshape(1, -1)\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# main iteration\n",
        "\n",
        "log_interval = 5 # how often printouts appear\n",
        "for epoch in range(max_epochs):\n",
        "    t0 = time.perf_counter()\n",
        "    # training here\n",
        "    f.train()\n",
        "    n = x_train.shape[0]\n",
        "    b = batch_size\n",
        "    n_batch = n // b\n",
        "    loss = torch.zeros(1)\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # shuffle\n",
        "    idx = torch.randperm(n) #identity?\n",
        "\n",
        "    for i in range(n_batch):\n",
        "        idxb = idx[i * b:(i + 1) * b] #random permute based on batch number\n",
        "        xb, yb = x_train[idxb], y_train[idxb] #get that batch data\n",
        "        optimizer.zero_grad()\n",
        "        f_batch= f(xb,do_gradient=True,do_hessian = False) \n",
        "        #print(f_batch)\n",
        "        fbpx1 = ((f_batch[1])[:,1,:]) #y from the batch\n",
        "        fbpx2 = ((f_batch[1])[:,2,:]) #y from the batch\n",
        "        fbpx3 = ((f_batch[1])[:,3,:]) #y from the batch\n",
        "        fbpy1 = ((f_batch[1])[:,4,:]) #y from the batch\n",
        "        fbpy2 = ((f_batch[1])[:,5,:]) #y from the batch\n",
        "        fbpy3 = ((f_batch[1])[:,6,:]) #y from the batch\n",
        "        fbqx1 = ((f_batch[1])[:,7,:]) #y from the batch\n",
        "        fbqx2 = ((f_batch[1])[:,8,:]) #y from the batch\n",
        "        fbqx3 = ((f_batch[1])[:,9,:]) #y from the batch\n",
        "        fbqy1 = ((f_batch[1])[:,10,:]) #y from the batch\n",
        "        fbqy2 = ((f_batch[1])[:,11,:]) #y from the batch\n",
        "        fbqy3 = ((f_batch[1])[:,12,:]) #y from the batch\n",
        "        \n",
        "        # unstable?     -> huh?\n",
        "        px1TimeOneVal = 1 * stepSize*fbqx1  + xb[:,1:2]\n",
        "        px2TimeOneVal = 1 * stepSize*fbqx2 + xb[:,2:3]\n",
        "        px3TimeOneVal = 1 *stepSize*fbqx3  + xb[:,3:4]\n",
        "        py1TimeOneVal = 1 * stepSize*fbqy1 + xb[:,4:5]\n",
        "        py2TimeOneVal = 1 * stepSize*fbqy2  + xb[:,5:6]\n",
        "        py3TimeOneVal = 1 * stepSize*fbqy3 + xb[:,6:7]\n",
        "        qx1TimeOneVal = -1 * stepSize*fbpx1  + xb[:,7:8]\n",
        "        qx2TimeOneVal = -1 * stepSize*fbpx2 + xb[:,8:9]\n",
        "        qx3TimeOneVal = -1 * stepSize*fbpx3  + xb[:,9:10]\n",
        "        qy1TimeOneVal = -1 * stepSize*fbpy1 + xb[:,10:11]\n",
        "        qy2TimeOneVal = -1 * stepSize*fbpy2  + xb[:,11:12]\n",
        "        qy3TimeOneVal = -1 * stepSize*fbpy3 + xb[:,12:13]\n",
        "\n",
        "        # stable\n",
        "        # yTimeOneVal = stepSize*fb2  + xb[:,1:2]\n",
        "        # zTimeOneVal = -1 * stepSize*yTimeOneVal + xb[:,2:3] # think about higher order verlet\n",
        "        loss = mse_loss(torch.cat((px1TimeOneVal,px2TimeOneVal,px3TimeOneVal,py1TimeOneVal,py2TimeOneVal,py3TimeOneVal,qx1TimeOneVal,qx2TimeOneVal,qx3TimeOneVal,qy1TimeOneVal,qy2TimeOneVal,qy3TimeOneVal),dim=1),yb)\n",
        "        running_loss += b * loss.item()\n",
        "\n",
        "        # update network weights\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "    running_loss = (running_loss / n,)\n",
        "    \n",
        "    t1 = time.perf_counter()\n",
        "\n",
        "    # test\n",
        "    fc_train= f(x_train,do_gradient=True,do_hessian = False)\n",
        "\n",
        "    px1TimeOneVal = 1 * stepSize*fc_train[1][:,7,:].detach()  + x_train[:,1:2]\n",
        "    px2TimeOneVal = 1 * stepSize*fc_train[1][:,8,:].detach() + x_train[:,2:3]\n",
        "    px3TimeOneVal = 1 *stepSize*fc_train[1][:,9,:].detach()  + x_train[:,3:4]\n",
        "    py1TimeOneVal = 1 * stepSize*fc_train[1][:,10,:].detach() + x_train[:,4:5]\n",
        "    py2TimeOneVal = 1 * stepSize*fc_train[1][:,11,:].detach()  + x_train[:,5:6]\n",
        "    py3TimeOneVal = 1 * stepSize*fc_train[1][:,12,:].detach() + x_train[:,6:7]\n",
        "    qx1TimeOneVal = -1 * stepSize*fc_train[1][:,1,:].detach()  + x_train[:,7:8]\n",
        "    qx2TimeOneVal = -1 * stepSize*fc_train[1][:,2,:].detach() + x_train[:,8:9]\n",
        "    qx3TimeOneVal = -1 * stepSize*fc_train[1][:,3,:].detach()  + x_train[:,9:10]\n",
        "    qy1TimeOneVal = -1 * stepSize*fc_train[1][:,4,:].detach() + x_train[:,10:11]\n",
        "    qy2TimeOneVal = -1 * stepSize*fc_train[1][:,5,:].detach()  + x_train[:,11:12]\n",
        "    qy3TimeOneVal = -1 * stepSize*fc_train[1][:,6,:].detach() + x_train[:,12:13]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    loss_train = mse_loss(torch.cat((px1TimeOneVal,px2TimeOneVal,px3TimeOneVal,py1TimeOneVal,py2TimeOneVal,py3TimeOneVal,qx1TimeOneVal,qx2TimeOneVal,qx3TimeOneVal,qy1TimeOneVal,qy2TimeOneVal,qy3TimeOneVal),dim=1),y_train)\n",
        "\n",
        "    fc_val= f(x_val,do_gradient=True,do_hessian = False)\n",
        "\n",
        "    px1TimeOneVal = 1 * stepSize*fc_val[1][:,7,:].detach()  + x_val[:,1:2]\n",
        "    px2TimeOneVal = 1 * stepSize*fc_val[1][:,8,:].detach() + x_val[:,2:3]\n",
        "    px3TimeOneVal = 1 *stepSize*fc_val[1][:,9,:].detach()  + x_val[:,3:4]\n",
        "    py1TimeOneVal = 1 * stepSize*fc_val[1][:,10,:].detach() + x_val[:,4:5]\n",
        "    py2TimeOneVal = 1 * stepSize*fc_val[1][:,11,:].detach()  + x_val[:,5:6]\n",
        "    py3TimeOneVal = 1 * stepSize*fc_val[1][:,12,:].detach() + x_val[:,6:7]\n",
        "    qx1TimeOneVal = -1 * stepSize*fc_val[1][:,1,:].detach()  + x_val[:,7:8]\n",
        "    qx2TimeOneVal = -1 * stepSize*fc_val[1][:,2,:].detach() + x_val[:,8:9]\n",
        "    qx3TimeOneVal = -1 * stepSize*fc_val[1][:,3,:].detach()  + x_val[:,9:10]\n",
        "    qy1TimeOneVal = -1 * stepSize*fc_val[1][:,4,:].detach() + x_val[:,10:11]\n",
        "    qy2TimeOneVal = -1 * stepSize*fc_val[1][:,5,:].detach()  + x_val[:,11:12]\n",
        "    qy3TimeOneVal = -1 * stepSize*fc_val[1][:,6,:].detach() + x_val[:,12:13]\n",
        "\n",
        "    loss_val = mse_loss(torch.cat((px1TimeOneVal,px2TimeOneVal,px3TimeOneVal,py1TimeOneVal,py2TimeOneVal,py3TimeOneVal,qx1TimeOneVal,qx2TimeOneVal,qx3TimeOneVal,qy1TimeOneVal,qy2TimeOneVal,qy3TimeOneVal),dim=1),y_val)\n",
        "\n",
        "    t = t1-t0\n",
        "    his_iter = (epoch, t1 - t0) + ('|',) + running_loss + ('|',) + (loss_train.item(),) + ('|',) + (loss_val.item(),)\n",
        "    if epoch % log_interval == 0:\n",
        "      print(printouts_frmt.format(*his_iter))\n",
        "\n",
        "    # store history\n",
        "    idx = [idx for idx, n in enumerate(np.array([x for x in printouts_str if not (x == '|')])) if n == 'loss'][1]\n",
        "    his = np.concatenate((his, np.array([x for x in his_iter if not (x == '|')]).reshape(1, -1)), axis=0)\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# overall performance on test data\n",
        "f_test= f(x_test,do_gradient=True,do_hessian = False)\n",
        "px1TimeOneVal = 1 * stepSize*f_test[1][:,7,:].detach()  + x_test[:,1:2]\n",
        "px2TimeOneVal = 1 * stepSize*f_test[1][:,8,:].detach() + x_test[:,2:3]\n",
        "px3TimeOneVal = 1 *stepSize*f_test[1][:,9,:].detach()  + x_test[:,3:4]\n",
        "py1TimeOneVal = 1 * stepSize*f_test[1][:,10,:].detach() + x_test[:,4:5]\n",
        "py2TimeOneVal = 1 * stepSize*f_test[1][:,11,:].detach()  + x_test[:,5:6]\n",
        "py3TimeOneVal = 1 * stepSize*f_test[1][:,12,:].detach() + x_test[:,6:7]\n",
        "qx1TimeOneVal = -1 * stepSize*f_test[1][:,1,:].detach()  + x_test[:,7:8]\n",
        "qx2TimeOneVal = -1 * stepSize*f_test[1][:,2,:].detach() + x_test[:,8:9]\n",
        "qx3TimeOneVal = -1 * stepSize*f_test[1][:,3,:].detach()  + x_test[:,9:10]\n",
        "qy1TimeOneVal = -1 * stepSize*f_test[1][:,4,:].detach() + x_test[:,10:11]\n",
        "qy2TimeOneVal = -1 * stepSize*f_test[1][:,5,:].detach()  + x_test[:,11:12]\n",
        "qy3TimeOneVal = -1 * stepSize*f_test[1][:,6,:].detach() + x_test[:,12:13]\n",
        "\n",
        "loss_test = mse_loss(torch.cat((px1TimeOneVal,px2TimeOneVal,px3TimeOneVal,py1TimeOneVal,py2TimeOneVal,py3TimeOneVal,qx1TimeOneVal,qx2TimeOneVal,qx3TimeOneVal,qy1TimeOneVal,qy2TimeOneVal,qy3TimeOneVal),dim=1),y_test)\n",
        "print('Test Loss: %0.4e' % loss.item())\n",
        "\n",
        "# convergence plots\n",
        "fig = plt.figure()\n",
        "linewidth = 3\n",
        "idx = [idx for idx, n in enumerate(np.array([x for x in printouts_str if not (x == '|')])) if n == 'loss'][1]\n",
        "\n",
        "plt.semilogy(his[1::, 0], his[1::, idx], linewidth=linewidth, label='f')\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('HINN Verlet Training Loss') \n",
        "plt.legend()\n",
        "plt.show()\n",
        "#fig.savefig('conv_plot.png',dpi=300) #to save the image"
      ],
      "metadata": {
        "id": "50wrighwuZ5J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7caf4c60-1f5e-4b24-ad41-019df88c0692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              | running        | train          | valid          \n",
            "epoch          time           | loss           | loss           | loss           \n",
            "0              0.0724         | 4.2031e-01     | 4.1964e-01     | 4.3675e-01     \n",
            "5              0.0608         | 4.1803e-01     | 4.1776e-01     | 3.5584e-01     \n",
            "10             0.0582         | 4.1696e-01     | 4.1681e-01     | 3.0224e-01     \n",
            "15             0.0591         | 4.1636e-01     | 4.1628e-01     | 2.6813e-01     \n",
            "20             0.0602         | 4.1602e-01     | 4.1596e-01     | 2.4704e-01     \n",
            "25             0.0608         | 4.1580e-01     | 4.1577e-01     | 2.3395e-01     \n",
            "30             0.0607         | 4.1567e-01     | 4.1565e-01     | 2.2532e-01     \n",
            "35             0.0564         | 4.1557e-01     | 4.1555e-01     | 2.1880e-01     \n",
            "40             0.0593         | 4.1549e-01     | 4.1547e-01     | 2.1298e-01     \n",
            "45             0.0589         | 4.1541e-01     | 4.1539e-01     | 2.0720e-01     \n",
            "50             0.0569         | 4.1533e-01     | 4.1532e-01     | 2.0125e-01     \n",
            "55             0.0638         | 4.1525e-01     | 4.1524e-01     | 1.9509e-01     \n",
            "60             0.0620         | 4.1517e-01     | 4.1515e-01     | 1.8878e-01     \n",
            "65             0.0692         | 4.1507e-01     | 4.1505e-01     | 1.8244e-01     \n",
            "70             0.0626         | 4.1491e-01     | 4.1485e-01     | 1.7621e-01     \n",
            "75             0.0595         | 4.1337e-01     | 4.1318e-01     | 1.7019e-01     \n",
            "80             0.0684         | 4.1274e-01     | 4.1255e-01     | 1.6441e-01     \n",
            "85             0.0655         | 4.1194e-01     | 4.1199e-01     | 1.5932e-01     \n",
            "90             0.1235         | 4.1170e-01     | 4.1108e-01     | 1.5499e-01     \n",
            "95             0.1456         | 4.1086e-01     | 4.1026e-01     | 1.5142e-01     \n",
            "100            0.0769         | 4.0995e-01     | 4.0936e-01     | 1.4865e-01     \n",
            "105            0.1389         | 4.0881e-01     | 4.0845e-01     | 1.4705e-01     \n",
            "110            0.1095         | 4.0760e-01     | 4.0753e-01     | 1.4562e-01     \n",
            "115            0.1041         | 4.0656e-01     | 4.0630e-01     | 1.4370e-01     \n",
            "120            0.0820         | 4.0523e-01     | 4.0500e-01     | 1.4548e-01     \n",
            "125            0.0603         | 4.0358e-01     | 4.0303e-01     | 1.5286e-01     \n",
            "130            0.0593         | 4.0113e-01     | 4.0063e-01     | 1.6331e-01     \n",
            "135            0.0577         | 3.9732e-01     | 3.9543e-01     | 1.6811e-01     \n",
            "140            0.0567         | 3.9133e-01     | 4.0883e-01     | 1.7337e-01     \n",
            "145            0.0575         | 3.9653e-01     | 3.9440e-01     | 1.7446e-01     \n",
            "150            0.0609         | 3.9510e-01     | 3.9326e-01     | 1.6452e-01     \n",
            "155            0.0593         | 3.8841e-01     | 3.9112e-01     | 1.6136e-01     \n",
            "160            0.0602         | 3.9351e-01     | 3.9330e-01     | 1.6068e-01     \n",
            "165            0.0595         | 3.9126e-01     | 3.9026e-01     | 1.5199e-01     \n",
            "170            0.0625         | 3.8866e-01     | 3.8804e-01     | 1.4258e-01     \n",
            "175            0.0585         | 3.8646e-01     | 3.8589e-01     | 1.3316e-01     \n",
            "180            0.0659         | 3.8296e-01     | 3.8229e-01     | 1.2726e-01     \n",
            "185            0.0584         | 3.7887e-01     | 3.7803e-01     | 1.2671e-01     \n",
            "190            0.0594         | 3.7401e-01     | 3.7224e-01     | 1.2654e-01     \n",
            "195            0.0642         | 3.6209e-01     | 3.6090e-01     | 1.2434e-01     \n",
            "200            0.0583         | 3.5866e-01     | 3.5935e-01     | 1.2314e-01     \n",
            "205            0.0606         | 3.5384e-01     | 3.5291e-01     | 1.2125e-01     \n",
            "210            0.0594         | 3.5100e-01     | 3.5110e-01     | 1.2115e-01     \n",
            "215            0.0611         | 3.4966e-01     | 3.4864e-01     | 1.2049e-01     \n",
            "220            0.0620         | 3.4690e-01     | 3.4623e-01     | 1.1998e-01     \n",
            "225            0.0595         | 3.4464e-01     | 3.4434e-01     | 1.1975e-01     \n",
            "230            0.0587         | 3.4327e-01     | 3.4311e-01     | 1.1779e-01     \n",
            "235            0.0595         | 3.4211e-01     | 3.4188e-01     | 1.1428e-01     \n",
            "240            0.0589         | 3.4125e-01     | 3.4116e-01     | 1.1138e-01     \n",
            "245            0.0571         | 3.4021e-01     | 3.3992e-01     | 1.0771e-01     \n",
            "250            0.0598         | 3.3957e-01     | 3.3955e-01     | 1.0494e-01     \n",
            "255            0.0615         | 3.3872e-01     | 3.3853e-01     | 1.0255e-01     \n",
            "260            0.0664         | 3.3821e-01     | 3.3817e-01     | 1.0035e-01     \n",
            "265            0.0621         | 3.3782e-01     | 3.3768e-01     | 9.7186e-02     \n",
            "270            0.0596         | 3.3717e-01     | 3.3709e-01     | 9.4137e-02     \n",
            "275            0.0600         | 3.3689e-01     | 3.3687e-01     | 9.1257e-02     \n",
            "280            0.0620         | 3.3721e-01     | 3.3730e-01     | 8.9123e-02     \n",
            "285            0.0675         | 3.3617e-01     | 3.3620e-01     | 8.6650e-02     \n",
            "290            0.0577         | 3.3613e-01     | 3.3589e-01     | 8.3816e-02     \n",
            "295            0.0581         | 3.3592e-01     | 3.3581e-01     | 8.1502e-02     \n",
            "300            0.0580         | 3.3549e-01     | 3.3551e-01     | 7.9510e-02     \n",
            "305            0.0631         | 3.3518e-01     | 3.3513e-01     | 7.7423e-02     \n",
            "310            0.0622         | 3.3506e-01     | 3.3500e-01     | 7.5453e-02     \n",
            "315            0.0639         | 3.3474e-01     | 3.3470e-01     | 7.3592e-02     \n",
            "320            0.0632         | 3.3460e-01     | 3.3457e-01     | 7.2046e-02     \n",
            "325            0.0591         | 3.3450e-01     | 3.3448e-01     | 7.0917e-02     \n",
            "330            0.0616         | 3.3446e-01     | 3.3444e-01     | 6.9859e-02     \n",
            "335            0.0587         | 3.3414e-01     | 3.3404e-01     | 6.9022e-02     \n",
            "340            0.0597         | 3.3381e-01     | 3.3379e-01     | 6.8238e-02     \n",
            "345            0.0612         | 3.3379e-01     | 3.3381e-01     | 6.7470e-02     \n",
            "350            0.0582         | 3.3389e-01     | 3.3386e-01     | 6.6772e-02     \n",
            "355            0.0602         | 3.3346e-01     | 3.3336e-01     | 6.6084e-02     \n",
            "360            0.0747         | 3.3327e-01     | 3.3329e-01     | 6.5473e-02     \n",
            "365            0.0676         | 3.3326e-01     | 3.3321e-01     | 6.4884e-02     \n",
            "370            0.0593         | 3.3299e-01     | 3.3294e-01     | 6.4290e-02     \n",
            "375            0.0621         | 3.3282e-01     | 3.3280e-01     | 6.3734e-02     \n",
            "380            0.0620         | 3.3276e-01     | 3.3277e-01     | 6.3181e-02     \n",
            "385            0.0599         | 3.3304e-01     | 3.3323e-01     | 6.2607e-02     \n",
            "390            0.0629         | 3.3313e-01     | 3.3273e-01     | 6.2090e-02     \n",
            "395            0.0590         | 3.3271e-01     | 3.3276e-01     | 6.1568e-02     \n",
            "400            0.0590         | 3.3227e-01     | 3.3233e-01     | 6.0950e-02     \n",
            "405            0.0608         | 3.3224e-01     | 3.3215e-01     | 6.0339e-02     \n",
            "410            0.0578         | 3.3219e-01     | 3.3215e-01     | 5.9683e-02     \n",
            "415            0.0611         | 3.3197e-01     | 3.3198e-01     | 5.8981e-02     \n",
            "420            0.0592         | 3.3190e-01     | 3.3186e-01     | 5.8266e-02     \n",
            "425            0.0695         | 3.3179e-01     | 3.3178e-01     | 5.7507e-02     \n",
            "430            0.0626         | 3.3169e-01     | 3.3167e-01     | 5.6712e-02     \n",
            "435            0.0591         | 3.3159e-01     | 3.3157e-01     | 5.5869e-02     \n",
            "440            0.0611         | 3.3151e-01     | 3.3149e-01     | 5.4981e-02     \n",
            "445            0.0610         | 3.3144e-01     | 3.3143e-01     | 5.4033e-02     \n",
            "450            0.0588         | 3.3145e-01     | 3.3147e-01     | 5.3058e-02     \n",
            "455            0.0574         | 3.3170e-01     | 3.3180e-01     | 5.2034e-02     \n",
            "460            0.0559         | 3.3141e-01     | 3.3123e-01     | 5.1021e-02     \n",
            "465            0.0592         | 3.3120e-01     | 3.3124e-01     | 4.9983e-02     \n",
            "470            0.0576         | 3.3103e-01     | 3.3097e-01     | 4.8894e-02     \n",
            "475            0.0608         | 3.3097e-01     | 3.3097e-01     | 4.7863e-02     \n",
            "480            0.0596         | 3.3084e-01     | 3.3080e-01     | 4.6836e-02     \n",
            "485            0.0623         | 3.3075e-01     | 3.3075e-01     | 4.5830e-02     \n",
            "490            0.0633         | 3.3068e-01     | 3.3066e-01     | 4.4869e-02     \n",
            "495            0.0596         | 3.3058e-01     | 3.3056e-01     | 4.3957e-02     \n",
            "500            0.0616         | 3.3050e-01     | 3.3049e-01     | 4.3064e-02     \n",
            "505            0.0600         | 3.3044e-01     | 3.3043e-01     | 4.2200e-02     \n",
            "510            0.0589         | 3.3041e-01     | 3.3042e-01     | 4.1385e-02     \n",
            "515            0.0658         | 3.3059e-01     | 3.3070e-01     | 4.0605e-02     \n",
            "520            0.0598         | 3.3083e-01     | 3.3063e-01     | 3.9864e-02     \n",
            "525            0.0606         | 3.3015e-01     | 3.3021e-01     | 3.9176e-02     \n",
            "530            0.0620         | 3.3022e-01     | 3.3012e-01     | 3.8466e-02     \n",
            "535            0.0598         | 3.3005e-01     | 3.3007e-01     | 3.7792e-02     \n",
            "540            0.0617         | 3.2994e-01     | 3.2991e-01     | 3.7201e-02     \n",
            "545            0.0614         | 3.2989e-01     | 3.2988e-01     | 3.6607e-02     \n",
            "550            0.0608         | 3.2979e-01     | 3.2977e-01     | 3.6043e-02     \n",
            "555            0.0595         | 3.2973e-01     | 3.2972e-01     | 3.5543e-02     \n",
            "560            0.0586         | 3.2965e-01     | 3.2964e-01     | 3.5064e-02     \n",
            "565            0.0653         | 3.2958e-01     | 3.2956e-01     | 3.4615e-02     \n",
            "570            0.0603         | 3.2952e-01     | 3.2950e-01     | 3.4218e-02     \n",
            "575            0.0633         | 3.2945e-01     | 3.2944e-01     | 3.3864e-02     \n",
            "580            0.0646         | 3.2939e-01     | 3.2938e-01     | 3.3525e-02     \n",
            "585            0.0631         | 3.2934e-01     | 3.2933e-01     | 3.3243e-02     \n",
            "590            0.0593         | 3.2934e-01     | 3.2935e-01     | 3.2932e-02     \n",
            "595            0.0600         | 3.2951e-01     | 3.2955e-01     | 3.2749e-02     \n",
            "600            0.0604         | 3.2950e-01     | 3.2939e-01     | 3.2435e-02     \n",
            "605            0.0594         | 3.2907e-01     | 3.2909e-01     | 3.2288e-02     \n",
            "610            0.0587         | 3.2914e-01     | 3.2909e-01     | 3.2160e-02     \n",
            "615            0.0634         | 3.2895e-01     | 3.2894e-01     | 3.1986e-02     \n",
            "620            0.0591         | 3.2894e-01     | 3.2892e-01     | 3.1839e-02     \n",
            "625            0.0590         | 3.2883e-01     | 3.2882e-01     | 3.1775e-02     \n",
            "630            0.2075         | 3.2879e-01     | 3.2878e-01     | 3.1748e-02     \n",
            "635            0.0585         | 3.2872e-01     | 3.2871e-01     | 3.1662e-02     \n",
            "640            0.0607         | 3.2866e-01     | 3.2865e-01     | 3.1636e-02     \n",
            "645            0.0630         | 3.2861e-01     | 3.2860e-01     | 3.1665e-02     \n",
            "650            0.0581         | 3.2855e-01     | 3.2854e-01     | 3.1613e-02     \n",
            "655            0.0612         | 3.2849e-01     | 3.2848e-01     | 3.1727e-02     \n",
            "660            0.0631         | 3.2843e-01     | 3.2842e-01     | 3.1718e-02     \n",
            "665            0.0621         | 3.2837e-01     | 3.2836e-01     | 3.1917e-02     \n",
            "670            0.0690         | 3.2831e-01     | 3.2830e-01     | 3.1893e-02     \n",
            "675            0.0625         | 3.2828e-01     | 3.2827e-01     | 3.2078e-02     \n",
            "680            0.0652         | 3.2832e-01     | 3.2835e-01     | 3.1999e-02     \n",
            "685            0.0607         | 3.2854e-01     | 3.2855e-01     | 3.2049e-02     \n",
            "690            0.0648         | 3.2822e-01     | 3.2812e-01     | 3.1705e-02     \n",
            "695            0.0636         | 3.2808e-01     | 3.2810e-01     | 3.1607e-02     \n",
            "700            0.0602         | 3.2803e-01     | 3.2798e-01     | 3.1511e-02     \n",
            "705            0.0638         | 3.2792e-01     | 3.2793e-01     | 3.1311e-02     \n",
            "710            0.0639         | 3.2789e-01     | 3.2786e-01     | 3.1038e-02     \n",
            "715            0.0628         | 3.2780e-01     | 3.2779e-01     | 3.0850e-02     \n",
            "720            0.0637         | 3.2776e-01     | 3.2775e-01     | 3.0714e-02     \n",
            "725            0.0613         | 3.2770e-01     | 3.2769e-01     | 3.0442e-02     \n",
            "730            0.0616         | 3.2765e-01     | 3.2764e-01     | 3.0243e-02     \n",
            "735            0.0601         | 3.2760e-01     | 3.2759e-01     | 3.0064e-02     \n",
            "740            0.0637         | 3.2755e-01     | 3.2754e-01     | 2.9606e-02     \n",
            "745            0.0619         | 3.2750e-01     | 3.2749e-01     | 2.9526e-02     \n",
            "750            0.0629         | 3.2746e-01     | 3.2745e-01     | 2.9246e-02     \n",
            "755            0.0586         | 3.2743e-01     | 3.2744e-01     | 2.9211e-02     \n",
            "760            0.0634         | 3.2751e-01     | 3.2754e-01     | 2.8618e-02     \n",
            "765            0.0624         | 3.2767e-01     | 3.2765e-01     | 2.8842e-02     \n",
            "770            0.0648         | 3.2729e-01     | 3.2724e-01     | 2.8335e-02     \n",
            "775            0.0612         | 3.2729e-01     | 3.2730e-01     | 2.7979e-02     \n",
            "780            0.0636         | 3.2722e-01     | 3.2718e-01     | 2.7892e-02     \n",
            "785            0.0586         | 3.2710e-01     | 3.2709e-01     | 2.7684e-02     \n",
            "790            0.0657         | 3.2708e-01     | 3.2708e-01     | 2.7415e-02     \n",
            "795            0.0600         | 3.2702e-01     | 3.2700e-01     | 2.7383e-02     \n",
            "800            0.0596         | 3.2695e-01     | 3.2693e-01     | 2.7094e-02     \n",
            "805            0.0616         | 3.2689e-01     | 3.2688e-01     | 2.7042e-02     \n",
            "810            0.0648         | 3.2684e-01     | 3.2683e-01     | 2.6669e-02     \n",
            "815            0.0628         | 3.2680e-01     | 3.2680e-01     | 2.6530e-02     \n",
            "820            0.0605         | 3.2686e-01     | 3.2692e-01     | 2.6092e-02     \n",
            "825            0.0624         | 3.2754e-01     | 3.2770e-01     | 2.6428e-02     \n",
            "830            0.0609         | 3.2673e-01     | 3.2680e-01     | 2.5897e-02     \n",
            "835            0.0698         | 3.2681e-01     | 3.2665e-01     | 2.5370e-02     \n",
            "840            0.0618         | 3.2687e-01     | 3.2664e-01     | 2.5293e-02     \n",
            "845            0.0595         | 3.2683e-01     | 3.2658e-01     | 2.5253e-02     \n",
            "850            0.0619         | 3.2675e-01     | 3.2655e-01     | 2.4977e-02     \n",
            "855            0.0612         | 3.2661e-01     | 3.2649e-01     | 2.4873e-02     \n",
            "860            0.0637         | 3.2648e-01     | 3.2643e-01     | 2.4838e-02     \n",
            "865            0.0576         | 3.2640e-01     | 3.2640e-01     | 2.4632e-02     \n",
            "870            0.0579         | 3.2636e-01     | 3.2636e-01     | 2.4523e-02     \n",
            "875            0.0588         | 3.2632e-01     | 3.2633e-01     | 2.4510e-02     \n",
            "880            0.0579         | 3.2629e-01     | 3.2629e-01     | 2.4371e-02     \n",
            "885            0.0583         | 3.2625e-01     | 3.2625e-01     | 2.4194e-02     \n",
            "890            0.0587         | 3.2621e-01     | 3.2621e-01     | 2.4109e-02     \n",
            "895            0.0589         | 3.2617e-01     | 3.2617e-01     | 2.4008e-02     \n",
            "900            0.0593         | 3.2614e-01     | 3.2614e-01     | 2.3978e-02     \n",
            "905            0.0643         | 3.2612e-01     | 3.2612e-01     | 2.3799e-02     \n",
            "910            0.0597         | 3.2617e-01     | 3.2621e-01     | 2.3904e-02     \n",
            "915            0.0574         | 3.2651e-01     | 3.2655e-01     | 2.3523e-02     \n",
            "920            0.0729         | 3.2625e-01     | 3.2611e-01     | 2.3699e-02     \n",
            "925            0.0584         | 3.2605e-01     | 3.2610e-01     | 2.3667e-02     \n",
            "930            0.0599         | 3.2598e-01     | 3.2593e-01     | 2.3440e-02     \n",
            "935            0.0569         | 3.2594e-01     | 3.2594e-01     | 2.3416e-02     \n",
            "940            0.0572         | 3.2586e-01     | 3.2584e-01     | 2.3550e-02     \n",
            "945            0.0594         | 3.2583e-01     | 3.2583e-01     | 2.3577e-02     \n",
            "950            0.0633         | 3.2578e-01     | 3.2576e-01     | 2.3524e-02     \n",
            "955            0.0602         | 3.2573e-01     | 3.2573e-01     | 2.3527e-02     \n",
            "960            0.0594         | 3.2570e-01     | 3.2569e-01     | 2.3557e-02     \n",
            "965            0.0594         | 3.2565e-01     | 3.2564e-01     | 2.3561e-02     \n",
            "970            0.0593         | 3.2561e-01     | 3.2560e-01     | 2.3515e-02     \n",
            "975            0.0685         | 3.2556e-01     | 3.2556e-01     | 2.3561e-02     \n",
            "980            0.0618         | 3.2552e-01     | 3.2552e-01     | 2.3606e-02     \n",
            "985            0.0613         | 3.2550e-01     | 3.2550e-01     | 2.3349e-02     \n",
            "990            0.0586         | 3.2556e-01     | 3.2560e-01     | 2.3374e-02     \n",
            "995            0.0579         | 3.2597e-01     | 3.2613e-01     | 2.3694e-02     \n",
            "Test Loss: 3.2581e-01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# overall performance on test data\n",
        "fb= f(x_test,do_gradient=True,do_hessian = False)\n",
        "\n",
        "px1TimeOneVal = 1 * stepSize*fb[1][:,7,:].detach()  + x_test[:,1:2]\n",
        "px2TimeOneVal = 1 * stepSize*fb[1][:,8,:].detach() + x_test[:,2:3]\n",
        "px3TimeOneVal = 1 *stepSize*fb[1][:,9,:].detach()  + x_test[:,3:4]\n",
        "py1TimeOneVal = 1 * stepSize*fb[1][:,10,:].detach() + x_test[:,4:5]\n",
        "py2TimeOneVal = 1 * stepSize*fb[1][:,11,:].detach()  + x_test[:,5:6]\n",
        "py3TimeOneVal = 1 * stepSize*fb[1][:,12,:].detach() + x_test[:,6:7]\n",
        "qx1TimeOneVal = -1 * stepSize*fb[1][:,1,:].detach()  + x_test[:,7:8]\n",
        "qx2TimeOneVal = -1 * stepSize*fb[1][:,2,:].detach() + x_test[:,8:9]\n",
        "qx3TimeOneVal = -1 * stepSize*fb[1][:,3,:].detach()  + x_test[:,9:10]\n",
        "qy1TimeOneVal = -1 * stepSize*fb[1][:,4,:].detach() + x_test[:,10:11]\n",
        "qy2TimeOneVal = -1 * stepSize*fb[1][:,5,:].detach()  + x_test[:,11:12]\n",
        "qy3TimeOneVal = -1 * stepSize*fb[1][:,6,:].detach() + x_test[:,12:13]\n",
        "\n",
        "loss_test = mse_loss(torch.cat((px1TimeOneVal,px2TimeOneVal,px3TimeOneVal,py1TimeOneVal,py2TimeOneVal,py3TimeOneVal,qx1TimeOneVal,qx2TimeOneVal,qx3TimeOneVal,qy1TimeOneVal,qy2TimeOneVal,qy3TimeOneVal),dim=1),y_test)\n",
        "\n",
        "print('Test Loss: %0.4e' % loss.item())"
      ],
      "metadata": {
        "id": "25JT0zHEu388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a278acf-46f9-487f-95ae-162307cfc967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 3.2581e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t, px1, px2,px3,py1,py2,py3,qx1,qx2,qx3,qy1,qy2,qy3 = x_train[0:1,0:1], x_train[0:1,1:2], x_train[0:1,2:3] ,x_train[0:1,3:4],x_train[0:1,4:5], x_train[0:1,5:6] ,x_train[0:1,6:7],x_train[0:1,7:8], x_train[0:1,8:9] ,x_train[0:1,9:10],x_train[0:1,10:11], x_train[0:1,11:12] ,x_train[0:1,12:13],\n",
        "steps = n_samples\n",
        "h = stepSize\n",
        "sol = torch.zeros(steps,14)\n",
        "for i in range(steps):\n",
        "\n",
        "  fb = f(torch.cat((t, px1, px2,px3,py1,py2,py3,qx1,qx2,qx3,qy1,qy2,qy3),dim=1),do_gradient=True,do_hessian = False)\n",
        "  fb1 = fb[1][:,1:2,0].detach()\n",
        "  fb2 = fb[1][:,2:3,0].detach()\n",
        "  fb3 = fb[1][:,3:4,0].detach()\n",
        "  fb4 = fb[1][:,4:5,0].detach()\n",
        "  fb5 = fb[1][:,5:6,0].detach()\n",
        "  fb6 = fb[1][:,6:7,0].detach()\n",
        "  fb7 = fb[1][:,7:8,0].detach()\n",
        "  fb8 = fb[1][:,8:9,0].detach()\n",
        "  fb9 = fb[1][:,9:10,0].detach()\n",
        "  fb10 = fb[1][:,10:11,0].detach()\n",
        "  fb11 = fb[1][:,11:12,0].detach()\n",
        "  fb12 = fb[1][:,12:13,0].detach()\n",
        "\n",
        "\n",
        "  px1 = h*fb1  + px1\n",
        "  px2 = h*fb2  + px2\n",
        "  px3 = h*fb3  + px3\n",
        "  py1 = h*fb4  + py1\n",
        "  py2 = h*fb5  + py2\n",
        "  py3 = h*fb6  + py3\n",
        "  qx1 = -1 * h*fb7  + qx1\n",
        "  qx2 = -1 * h*fb8  + qx2\n",
        "  qx3 = -1 * h* fb9  + qx3\n",
        "  qy1 = -1 * h*fb10 + qy1\n",
        "  qy2 = -1 * h*fb11  + qy2\n",
        "  qy3 = -1 * h*fb12  + qy3\n",
        "  t = t + h\n",
        "  sol[i:i+1,:] =  torch.cat((t, px1, px2,px3,py1,py2,py3,qx1,qx2,qx3,qy1,qy2,qy3,fb[0].detach()),dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ENgG45awu36U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(sol[:,0].detach().numpy(),sol[:,1].detach().numpy(),sol[:,0].detach().numpy(),sol[:,2].detach().numpy(),\n",
        "         x_train[1:steps,0].detach().numpy(),y_train[1:steps:,0].detach().numpy(),\n",
        "         x_train[1:steps,0].detach().numpy(),y_train[1:steps:,1].detach().numpy())\n",
        "\n",
        "plt.title(\"RK4 SHO\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.legend(['learned y','learned z','true y', 'true z'])\n",
        "plt.show()\n",
        "#fig.savefig('conv_plot2.png',dpi=300) #to save the image"
      ],
      "metadata": {
        "id": "_YpZVq4-u33P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(sol[:,1],sol[:,2], sol[:,0], (x_train[0:steps,1]**2 + x_train[0:steps,2]**2).detach().numpy(),\n",
        "                sol[:,0], (sol[:,1]**2 + sol[:,2]**2)  )\n",
        "plt.title(\"RK4 SHO\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.legend('y','z')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-p23KUVWu30m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}