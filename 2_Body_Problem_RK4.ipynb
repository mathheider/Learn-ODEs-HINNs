{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb_RbZIQtT3l",
        "outputId": "5ec51edd-8012-4e5d-b80a-f96f5ce48dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tikzplotlib\n",
            "  Downloading tikzplotlib-0.10.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tikzplotlib) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tikzplotlib) (7.1.2)\n",
            "Collecting webcolors\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from tikzplotlib) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->tikzplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->tikzplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->tikzplotlib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.4.0->tikzplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->tikzplotlib) (1.15.0)\n",
            "Installing collected packages: webcolors, tikzplotlib\n",
            "Successfully installed tikzplotlib-0.10.1 webcolors-1.12\n",
            "Default data type: torch.float64\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "from scipy.integrate import solve_ivp\n",
        "!pip install tikzplotlib #uncomment for saving nice images\n",
        "import tikzplotlib\n",
        "from pylab import *\n",
        "# set precision\n",
        "torch.set_default_dtype(torch.float64)\n",
        "print('Default data type:', torch.get_default_dtype())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN6WkMOZ3ZzS"
      },
      "outputs": [],
      "source": [
        "import os, torch, pickle, zipfile, sys\n",
        "import imageio, shutil\n",
        "import scipy, scipy.misc, scipy.integrate\n",
        "solve_ivp = scipy.integrate.solve_ivp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEbej7jguKLP",
        "outputId": "1748c7e5-8c86-4532-8962-060e1bdfe23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hessquik\n",
            "  Downloading hessQuik-0.0.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from hessquik) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->hessquik) (4.4.0)\n",
            "Installing collected packages: hessquik\n",
            "Successfully installed hessquik-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install hessquik\n",
        "import hessQuik.activations as act\n",
        "import hessQuik.layers as lay\n",
        "import hessQuik.networks as net\n",
        "from hessQuik.utils import  test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNHlK2_c3cL5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create dataset for models: functions for the different energies, dynamics, bodies, and their orbits\n",
        "\n",
        "  Code from:\n",
        "  Hamiltonian Neural Networks | 2019\n",
        "  Sam Greydanus, Misko Dzamba, Jason Yosinski\n",
        "https://github.com/greydanus/hamiltonian-nn/blob/master/experiment-2body/data.py\n",
        "'''\n",
        "\n",
        "\n",
        "def to_pickle(thing, path): # save something\n",
        "    with open(path, 'wb') as handle:\n",
        "        pickle.dump(thing, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "def from_pickle(path): # load something\n",
        "    thing = None\n",
        "    with open(path, 'rb') as handle:\n",
        "        thing = pickle.load(handle)\n",
        "    return thing\n",
        "\n",
        "##### ENERGY #####\n",
        "def potential_energy(state):\n",
        "    '''U=sum_i,j>i G m_i m_j / r_ij'''\n",
        "    tot_energy = np.zeros((1,1,state.shape[2]))\n",
        "    for i in range(state.shape[0]):\n",
        "        for j in range(i+1,state.shape[0]):\n",
        "            r_ij = ((state[i:i+1,1:3] - state[j:j+1,1:3])**2).sum(1, keepdims=True)**.5\n",
        "            m_i = state[i:i+1,0:1]\n",
        "            m_j = state[j:j+1,0:1]\n",
        "    tot_energy += m_i * m_j / r_ij\n",
        "    U = -tot_energy.sum(0).squeeze()\n",
        "    return U\n",
        "\n",
        "def kinetic_energy(state):\n",
        "    '''T=sum_i .5*m*v^2'''\n",
        "    energies = .5 * state[:,0:1] * (state[:,3:5]**2).sum(1, keepdims=True)\n",
        "    T = energies.sum(0).squeeze()\n",
        "    return T\n",
        "\n",
        "def total_energy(state):\n",
        "    return potential_energy(state) + kinetic_energy(state)\n",
        "\n",
        "\n",
        "##### DYNAMICS #####\n",
        "def get_accelerations(state, epsilon=0):\n",
        "    # shape of state is [bodies x properties]\n",
        "    net_accs = [] # [nbodies x 2]\n",
        "    for i in range(state.shape[0]): # number of bodies\n",
        "        other_bodies = np.concatenate([state[:i, :], state[i+1:, :]], axis=0)\n",
        "        displacements = other_bodies[:, 1:3] - state[i, 1:3] # indexes 1:3 -> pxs, pys\n",
        "        distances = (displacements**2).sum(1, keepdims=True)**0.5\n",
        "        masses = other_bodies[:, 0:1] # index 0 -> mass\n",
        "        pointwise_accs = masses * displacements / (distances**3 + epsilon) # G=1\n",
        "        net_acc = pointwise_accs.sum(0, keepdims=True)\n",
        "        net_accs.append(net_acc)\n",
        "    net_accs = np.concatenate(net_accs, axis=0)\n",
        "    return net_accs\n",
        "  \n",
        "def update(t, state):\n",
        "    state = state.reshape(-1,5) # [bodies, properties]\n",
        "    deriv = np.zeros_like(state)\n",
        "    deriv[:,1:3] = state[:,3:5] # dx, dy = vx, vy\n",
        "    deriv[:,3:5] = get_accelerations(state)\n",
        "    return deriv.reshape(-1)\n",
        "\n",
        "\n",
        "##### INTEGRATION SETTINGS #####\n",
        "#this is the function we will be using to get our data for the two bodies \n",
        "def get_orbit(state, update_fn=update, t_points=100, t_span=[0,2], **kwargs):\n",
        "    if not 'rtol' in kwargs.keys():\n",
        "        kwargs['rtol'] = 1e-9\n",
        "\n",
        "    orbit_settings = locals() #creates a dictionary of the local variables\n",
        "\n",
        "    nbodies = state.shape[0]\n",
        "    t_eval = np.linspace(t_span[0], t_span[1], t_points)\n",
        "    orbit_settings['t_eval'] = t_eval\n",
        "\n",
        "    path = solve_ivp(fun=update_fn, t_span=t_span, y0=state.flatten(),\n",
        "                     t_eval=t_eval, **kwargs)\n",
        "    orbit = path['y'].reshape(nbodies, 5, t_points)\n",
        "    #returns orbit: 3D array, for us 2 bodies, 5 values, for each timestep\n",
        "    # and orbit_settings: dictionary of local vars, state, update_fn, t_points, t_span, kwargs, t_eval\n",
        "    return orbit, orbit_settings\n",
        "\n",
        "\n",
        "##### INITIALIZE THE TWO BODIES #####\n",
        "def random_config(orbit_noise=5e-2, min_radius=0.5, max_radius=1.5):\n",
        "    state = np.zeros((2,5))\n",
        "    state[:,0] = 1\n",
        "    pos = np.random.rand(2) * (max_radius-min_radius) + min_radius\n",
        "    r = np.sqrt( np.sum((pos**2)) )\n",
        "\n",
        "    # velocity that yields a circular orbit\n",
        "    vel = np.flipud(pos) / (2 * r**1.5)\n",
        "    vel[0] *= -1\n",
        "    vel *= 1 + orbit_noise*np.random.randn()\n",
        "\n",
        "    # make the circular orbits SLIGHTLY elliptical\n",
        "    state[:,1:3] = pos\n",
        "    state[:,3:5] = vel\n",
        "    state[1,1:] *= -1\n",
        "    return state\n",
        "\n",
        "\n",
        "##### HELPER FUNCTION #####\n",
        "def coords2state(coords, nbodies=2, mass=1):\n",
        "    timesteps = coords.shape[0]\n",
        "    state = coords.T\n",
        "    state = state.reshape(-1, nbodies, timesteps).transpose(1,0,2)\n",
        "    mass_vec = mass * np.ones((nbodies, 1, timesteps))\n",
        "    state = np.concatenate([mass_vec, state], axis=1)\n",
        "    return state\n",
        "\n",
        "\n",
        "##### INTEGRATE AN ORBIT OR TWO #####\n",
        "def sample_orbits(timesteps=4001, trials=1, nbodies=2, orbit_noise=5e-2,\n",
        "                  min_radius=0.5, max_radius=1.5, t_span=[0, 20], verbose=False, **kwargs):\n",
        "    \n",
        "    orbit_settings = locals()\n",
        "    if verbose:\n",
        "        print(\"Making a dataset of near-circular 2-body orbits:\")\n",
        "    \n",
        "    x, dx, e = [], [], []\n",
        "    N = timesteps*trials\n",
        "    while len(x) < N:\n",
        "\n",
        "        state = random_config(orbit_noise, min_radius, max_radius)\n",
        "        orbit, settings, t_eval = get_orbit(state, t_points=timesteps, t_span=t_span, **kwargs)\n",
        "        batch = orbit.transpose(2,0,1).reshape(-1,10)\n",
        "\n",
        "        for state in batch:\n",
        "            dstate = update(None, state)\n",
        "            \n",
        "            # reshape from [nbodies, state] where state=[m, qx, qy, px, py]\n",
        "            # m is assumed to be 1\n",
        "            # to [canonical_coords] = [qx1, qx2, qy1, qy2, px1,px2,....]\n",
        "            coords = state.reshape(nbodies,5).T[1:].flatten()\n",
        "            dcoords = dstate.reshape(nbodies,5).T[1:].flatten() #derivatives\n",
        "            x.append(coords)\n",
        "            dx.append(dcoords)\n",
        "\n",
        "            shaped_state = state.copy().reshape(2,5,1)\n",
        "            e.append(total_energy(shaped_state))\n",
        "\n",
        "    data = {'coords': np.stack(x)[:N],\n",
        "            'dcoords': np.stack(dx)[:N],\n",
        "            'energy': np.stack(e)[:N] }\n",
        "    return data, orbit_settings\n",
        "\n",
        "\n",
        "##### MAKE A DATASET #####\n",
        "def make_orbits_dataset(test_split=0.2, **kwargs):\n",
        "    data, orbit_settings = sample_orbits(**kwargs)\n",
        "    \n",
        "    # make a train/test split\n",
        "    # split_ix = int(data['coords'].shape[0] * test_split)\n",
        "    # split_data = {}\n",
        "    # for k, v in data.items():\n",
        "    #     split_data[k], split_data['test_' + k] = v[split_ix:], v[:split_ix]\n",
        "    # data = split_data\n",
        "\n",
        "    data['meta'] = orbit_settings\n",
        "    return data\n",
        "\n",
        "\n",
        "##### LOAD OR SAVE THE DATASET #####\n",
        "def get_dataset(experiment_name, save_dir, **kwargs):\n",
        "    '''Returns an orbital dataset. Also constructs\n",
        "    the dataset if no saved version is available.'''\n",
        "\n",
        "    path = '{}/{}-orbits-dataset.pkl'.format(save_dir, experiment_name)\n",
        "\n",
        "    try:\n",
        "        data = from_pickle(path)\n",
        "        print(\"Successfully loaded data from {}\".format(path))\n",
        "    except:\n",
        "        print(\"Had a problem loading data from {}. Rebuilding dataset...\".format(path))\n",
        "        data = make_orbits_dataset(**kwargs)\n",
        "        to_pickle(data, path)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzUkvDgXqSD5",
        "outputId": "1e802043-abd8-4b36-93ea-f19b2e59fc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR4cXX2MdCMc"
      },
      "outputs": [],
      "source": [
        "np.random.seed(2)\n",
        "state = random_config()\n",
        "orbit, settings = get_orbit(state, t_points=4001, t_span = [0, 20], rtol = 1e-10) # this gives us the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaLZNJWq0iJA",
        "outputId": "f12b63cc-2c9b-494a-a8cd-47776a7b2487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "state\n",
            "update_fn\n",
            "t_points\n",
            "t_span\n",
            "kwargs\n",
            "t_eval\n",
            "2\n",
            "5\n",
            "4001\n"
          ]
        }
      ],
      "source": [
        "for x in settings:\n",
        "  print(x)\n",
        "#for y in orbit:\n",
        " # print(y)\n",
        "print(len(orbit))\n",
        "print(len(orbit[0]))\n",
        "print(len(orbit[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8s646yI5Pv-",
        "outputId": "8e688c4a-a430-4c18-f021-7586a89812c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stepsize= 0.005\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Set up training values \n",
        "\n",
        "'''\n",
        "\n",
        "n_train = 4000      # number of training points\n",
        "n_samples = n_train\n",
        "x_train = np.zeros([2,5,n_train])\n",
        "x_train[:,0,:] = settings['t_eval'][:n_train]\n",
        "x_train[:,1:5,:] = orbit[:,1:,:n_train]\n",
        "y_train = orbit[:,1:,1:n_train+1]\n",
        "x_train, y_train = torch.tensor(x_train), torch.tensor(y_train)\n",
        "# x_val, y_val = x_train[:,:,100:1000], y_train[:,:,100:1000]\n",
        "# x_test, y_test = x_train[:,:,100:3000], y_train[:,:,100:3000]\n",
        "\n",
        "#print(x_train.shape) #[2, 5, 4000]\n",
        "#print(y_train.shape) #[2, 4, 4000]\n",
        "\n",
        "# shuffle and split data\n",
        "# idx = torch.randperm(n_train + n_val + n_test)\n",
        "# x_train, y_train = x[idx[:n_train]], y[idx[:n_train]]\n",
        "# x_val, y_val = x[idx[n_train:n_train + n_val]], y[idx[n_train:n_train + n_val]]\n",
        "# x_test, y_test = x[idx[n_train + n_val:]], y[idx[n_train + n_val:]]\n",
        "\n",
        "stepSize = 20/4000\n",
        "print(\"stepsize=\", stepSize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9hAlQosuNd4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create our Network:\n",
        "  - our width and depth, as well as the function we use to create our ResNet\n",
        "\n",
        "'''\n",
        "\n",
        "width = 20\n",
        "depth = 3\n",
        "f = net.NN(lay.singleLayer(10, width, act=act.tanhActivation()),\n",
        "           net.resnetNN(width, depth, h=0.5, act=act.tanhActivation()),\n",
        "           lay.singleLayer(width, 1, act=act.identityActivation()))\n",
        "\n",
        "# Pytorch optimizer for the network weights\n",
        "optimizer = torch.optim.Adam(f.parameters(), lr=1e-3) \n",
        "#weight decay is for regularization weight_decay=1e-5 add this for regularization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uay37Wul87PB"
      },
      "source": [
        "### Transform x_train to nex-by-10 and y_train to nex-by-8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CI9w8_S2kaD"
      },
      "outputs": [],
      "source": [
        "#Transform x_train to nex-by-10 and y_train to nex-by-8\n",
        "\n",
        "x_train = torch.cat((x_train[0,:,:],x_train[1,:,:]),axis=0).t()\n",
        "y_train = torch.cat((y_train[0,:,:],y_train[1,:,:]),axis=0).t()\n",
        "x_val, y_val = x_train[100:1000,:], y_train[100:1000,:]\n",
        "x_test, y_test = x_train[100:3000,:], y_train[100:3000,:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.size()) #[4000, 10]\n",
        "print(x_val.size()) #[900, 10]\n",
        "print(x_test.size()) #[2900, 10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEJQMWJNVg_0",
        "outputId": "b1e92ee0-3fe2-4275-bf8b-1757178add85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4000, 10])\n",
            "torch.Size([900, 10])\n",
            "torch.Size([2900, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS6gPAfz6eeh",
        "outputId": "f053fb67-dd63-4e51-fc11-9d2e34fd7e0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4000, 10, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Neural Net on our Training data (f is our function to make the net)\n",
        "f_train = f(x_train,do_gradient=True,do_hessian = False) \n",
        "f_train[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZB9FhoK5WG5"
      },
      "outputs": [],
      "source": [
        "# Test Time stepping \n",
        "# Check this for RK4 \n",
        "y1 = stepSize*f_train[1][:,3:5,0]  + x_train[:,1:3] \n",
        "z1 = -1 * stepSize*f_train[1][:,1:3,0] + x_train[:,3:5] \n",
        "y2 = stepSize*f_train[1][:,8:10,0]  + x_train[:,6:8] \n",
        "z2 = -1 * stepSize*f_train[1][:,6:8,0] + x_train[:,8:10]\n",
        "y12z12 = torch.cat((y1,z1,y2,z2),dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngOGu5CuuaJS"
      },
      "outputs": [],
      "source": [
        "#Our Mean Squared Error Loss Function\n",
        "def mse_loss(y_true: torch.Tensor,y: torch.Tensor):\n",
        "  # return (0.5 / y.shape[0]) * torch.norm(y_true - y.view_as(y_true)) ** 2\n",
        "  return 0.5*torch.mean(torch.sum((y_true - y.view_as(y_true))** 2, dim = 1, keepdim=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDNvY0D9uZ_6"
      },
      "outputs": [],
      "source": [
        "#A function for printing the various headers necessary for seeing our network running\n",
        "def print_headers( verbose: bool = True):\n",
        "    r\"\"\"\n",
        "    Print headers for nice training\n",
        "    \"\"\"\n",
        "    loss_printouts = ('loss',)\n",
        "    n_loss = len(loss_printouts)\n",
        "\n",
        "    headers = (('', '', '|', 'running',) + (n_loss - 1) * ('',) + ('|', 'train',)\n",
        "               + (n_loss - 1) * ('',) + ('|', 'valid',) + (n_loss - 1) * ('',))\n",
        "\n",
        "    printouts = ('epoch', 'time') + 3 * (('|',) + loss_printouts)\n",
        "    printouts_frmt = '{:<15d}{:<15.4f}' + 3 * ('{:<2s}' + n_loss * '{:<15.4e}')\n",
        "\n",
        "    if verbose:\n",
        "        print(('{:<15s}{:<15s}' + 3 * ('{:<2s}' + n_loss * '{:<15s}')).format(*headers))\n",
        "        print(('{:<15s}{:<15s}' + 3 * ('{:<2s}' + n_loss * '{:<15s}')).format(*printouts))\n",
        "\n",
        "    return headers, printouts, printouts_frmt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stepRK4(f, x):\n",
        "  z = x.clone()\n",
        "  f_batch= f(z,do_gradient=True,do_hessian = False) #gradient and vals for this batch\n",
        "\n",
        "  k1y1= f_batch[1][:,1:3,0]\n",
        "  k1y2= f_batch[1][:,6:8,0]\n",
        "  k1z1= -f_batch[1][:,3:5,0]\n",
        "  k1z2= -f_batch[1][:,8:10,0]\n",
        "  xb1 = z + stepSize/2*torch.cat((torch.ones_like(z[:,0:1]), k1y1, k1z1,\n",
        "                                    torch.ones_like(z[:,5:6]), k1y2, k1z2), dim=1)\n",
        "  \n",
        "  fb1 = f(xb1,do_gradient=True,do_hessian = False)\n",
        "  k2y1= fb1[1][:,1:3,0]\n",
        "  k2y2= fb1[1][:,6:8,0]\n",
        "  k2z1= -fb1[1][:,3:5,0]\n",
        "  k2z2= -fb1[1][:,8:10,0]\n",
        "  xb2 = z + stepSize/2*torch.cat((torch.ones_like(z[:,0:1]), k2y1, k2z1,\n",
        "                                    torch.ones_like(z[:,5:6]), k2y2, k2z2), dim=1)\n",
        "  \n",
        "  fb2 = f(xb2,do_gradient=True,do_hessian = False)\n",
        "  k3y1= fb2[1][:,1:3,0]\n",
        "  k3y2= fb2[1][:,6:8,0]\n",
        "  k3z1= -fb2[1][:,3:5,0]\n",
        "  k3z2= -fb2[1][:,8:10,0]\n",
        "  xb3 = z + stepSize*torch.cat((torch.ones_like(z[:,0:1]), k3y1, k3z1,\n",
        "                                    torch.ones_like(z[:,5:6]), k3y2, k3z2), dim=1)\n",
        "  \n",
        "  fb3 = f(xb3,do_gradient=True,do_hessian = False)\n",
        "  k4y1= fb3[1][:,1:3,0]\n",
        "  k4y2= fb3[1][:,6:8,0]\n",
        "  k4z1= -fb3[1][:,3:5,0]\n",
        "  k4z2= -fb3[1][:,8:10,0]\n",
        "\n",
        "  y1 = stepSize/6*(k1z1+2*k2z1+2*k3z1+k4z1)  + z[:,1:3] \n",
        "  z1 = stepSize/6*(k1y1+2*k2y1+2*k3y1+k4y1)  + z[:,3:5] \n",
        "  y2 = stepSize/6*(k1z2+2*k2z2+2*k3z2+k4z2)   + z[:,6:8] \n",
        "  z2 = stepSize/6*(k1y2+2*k2y2+2*k3y2+k4y2)  + z[:,8:10]\n",
        "\n",
        "  return torch.cat((y1,z1,y2,z2),dim=1)"
      ],
      "metadata": {
        "id": "Dk362Cw2Ubpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "50wrighwuZ5J",
        "outputId": "0bdbf294-af30-4a95-b211-5c0d41af30a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              | running        | train          | valid          \n",
            "epoch          time           | loss           | loss           | loss           \n",
            "0              0.3200         | 1.6007e-08     | 1.5812e-08     | 1.0234e-08     \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d7675e16ce28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# update network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#back propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#step so we can then do the next batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "'''\n",
        "Training our Network\n",
        "  - Print the table detailing various losses over epochs, and produce a figure \n",
        "    showing the training loss as the epochs go on.\n",
        "\n",
        "'''\n",
        "\n",
        "# training parameters\n",
        "max_epochs = 1000\n",
        "batch_size = 500\n",
        "\n",
        "# get printouts\n",
        "headers, printouts_str, printouts_frmt = print_headers()\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# initial evaluation -> initial training values and gradient\n",
        "f_train = f(x_train,do_gradient=True,do_hessian = False) \n",
        "#now construct the neural nets for validation\n",
        "\n",
        "#For printing: \n",
        "his_iter = (-1, 0.0) + ('|',) + (0,) + ('|',) + (0,) + ('|',) + (0,)\n",
        "# print(printouts_frmt.format(*his_iter))\n",
        "\n",
        "# store history\n",
        "his = np.array([x for x in his_iter if not (x == '|')]).reshape(1, -1)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# main iteration of training \n",
        "\n",
        "log_interval = 5 # how often printouts appear\n",
        "totaltime = 0\n",
        "\n",
        "for epoch in range(max_epochs): #go through each epoch\n",
        "    t0 = time.perf_counter()\n",
        "    # training here\n",
        "    f.train()\n",
        "    n = x_train.shape[0] #number of inputs\n",
        "    b = batch_size\n",
        "    n_batch = n // b #inputs per batch\n",
        "    loss = torch.zeros(1) #initializing loss\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # shuffle\n",
        "    idx = torch.randperm(n) #identity\n",
        "\n",
        "    for i in range(n_batch): #loop through batches\n",
        "        idxb = idx[i * b:(i + 1) * b] #random permute based on batch number\n",
        "        xb, yb = x_train[idxb], y_train[idxb] #get that batch data\n",
        "        optimizer.zero_grad()\n",
        "        ystep = stepRK4(f, xb)\n",
        "        # f_batch= f(xb,do_gradient=True,do_hessian = False) #gradient and vals for this batch\n",
        "\n",
        "        # k1y1= f_batch[1][:,1:3,0]\n",
        "        # k1y2= f_batch[1][:,6:8,0]\n",
        "        # k1z1= -f_batch[1][:,3:5,0]\n",
        "        # k1z2= -f_batch[1][:,8:10,0]\n",
        "        # xb1 = xb + stepSize/2*torch.cat((torch.ones_like(xb[:,0:1]), k1y1, k1z1,\n",
        "        #                                  torch.ones_like(xb[:,5:6]), k1y2, k1z2), dim=1)\n",
        "        \n",
        "        # fb1 = f(xb1,do_gradient=True,do_hessian = False)\n",
        "        # k2y1= fb1[1][:,1:3,0]\n",
        "        # k2y2= fb1[1][:,6:8,0]\n",
        "        # k2z1= -fb1[1][:,3:5,0]\n",
        "        # k2z2= -fb1[1][:,8:10,0]\n",
        "        # xb2 = xb + stepSize/2*torch.cat((torch.ones_like(xb[:,0:1]), k2y1, k2z1,\n",
        "        #                                  torch.ones_like(xb[:,5:6]), k2y2, k2z2), dim=1)\n",
        "        \n",
        "        # fb2 = f(xb2,do_gradient=True,do_hessian = False)\n",
        "        # k3y1= fb2[1][:,1:3,0]\n",
        "        # k3y2= fb2[1][:,6:8,0]\n",
        "        # k3z1= -fb2[1][:,3:5,0]\n",
        "        # k3z2= -fb2[1][:,8:10,0]\n",
        "        # xb3 = xb + stepSize*torch.cat((torch.ones_like(xb[:,0:1]), k3y1, k3z1,\n",
        "        #                                  torch.ones_like(xb[:,5:6]), k3y2, k3z2), dim=1)\n",
        "        \n",
        "        # fb3 = f(xb3,do_gradient=True,do_hessian = False)\n",
        "        # k4y1= fb3[1][:,1:3,0]\n",
        "        # k4y2= fb3[1][:,6:8,0]\n",
        "        # k4z1= -fb3[1][:,3:5,0]\n",
        "        # k4z2= -fb3[1][:,8:10,0]\n",
        "\n",
        "        # y1 = stepSize/6*(k1z1+2*k2z1+2*k3z1+k4z1)  + xb[:,1:3] \n",
        "        # z1 = stepSize/6*(k1y1+2*k2y1+2*k3y1+k4y1)  + xb[:,3:5] \n",
        "        # y2 = stepSize/6*(k1z2+2*k2z2+2*k3z2+k4z2)   + xb[:,6:8] \n",
        "        # z2 = stepSize/6*(k1y2+2*k2y2+2*k3y2+k4y2)  + xb[:,8:10]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        '''\n",
        "        incorrect RK4 scheme\n",
        "        #time steps (like we saw earlier)\n",
        "        k1y1= stepSize / 6 * f_batch[1][:,1:3,0]\n",
        "        k2y1= stepSize / 3 * f_batch[1][:,1:3,0]+stepSize*k1y1/2\n",
        "        k3y1= stepSize / 3 * f_batch[1][:,1:3,0]+stepSize*k2y1/2\n",
        "        k4y1= stepSize / 6 * f_batch[1][:,1:3,0]+stepSize*k3y1\n",
        "\n",
        "        k1y2= stepSize / 6 *f_batch[1][:,6:8,0]\n",
        "        k2y2= stepSize / 3 * f_batch[1][:,6:8,0]+stepSize*k1y2/2\n",
        "        k3y2= stepSize / 3 * f_batch[1][:,6:8,0]+stepSize*k2y2/2\n",
        "        k4y2= stepSize / 6 * f_batch[1][:,6:8,0]+stepSize*k3y2\n",
        "\n",
        "        k1z1= stepSize / 6 * f_batch[1][:,3:5,0]\n",
        "        k2z1= stepSize / 3 * f_batch[1][:,3:5,0]+ stepSize*k1z1/2\n",
        "        k3z1= stepSize / 3 * f_batch[1][:,3:5,0]+stepSize*k2z1/2\n",
        "        k4z1= stepSize / 6 * f_batch[1][:,3:5,0]+stepSize*k3z1\n",
        "\n",
        "        k1z2= stepSize / 6 * f_batch[1][:,8:10,0]\n",
        "        k2z2= stepSize / 3 * f_batch[1][:,8:10,0]+stepSize*k1z2/2\n",
        "        k3z2= stepSize / 3 * f_batch[1][:,8:10,0]+stepSize*k2z2/2\n",
        "        k4z2= stepSize / 6 * f_batch[1][:,8:10,0]+stepSize*k3z2\n",
        "\n",
        "\n",
        "\n",
        "        y1 = stepSize*(k1z1+k2z1+k3z1+k4z1)  + xb[:,1:3] \n",
        "        z1 = -1 *stepSize*(k1y1+k2y1+k3y1+k4y1)  + xb[:,3:5] \n",
        "        y2 = stepSize*(k1z2+k2z2+k3z2+k4z2)   + xb[:,6:8] \n",
        "        z2 = -1 * stepSize*(k1y2+k2y2+k3y2+k4y2)  + xb[:,8:10]\n",
        "        '''\n",
        "        # torch.cat((y1,z1,y2,z2),dim=1).shape\n",
        "        loss = mse_loss(ystep,yb) \n",
        "        running_loss += b * loss.item()\n",
        "\n",
        "        # update network weights\n",
        "        loss.backward(retain_graph=True) #back propagation \n",
        "        optimizer.step() #step so we can then do the next batch\n",
        "\n",
        "    running_loss = (running_loss / n,) #averge it \n",
        "    \n",
        "    t1 = time.perf_counter()\n",
        "\n",
        "    # test\n",
        "    # fc_train= f(x_train,do_gradient=True,do_hessian = False)\n",
        "\n",
        "    # k1y1= stepSize / 6 * fc_train[1][:,1:3,0]\n",
        "    # k2y1= stepSize / 3 * fc_train[1][:,1:3,0]+stepSize*k1y1/2\n",
        "    # k3y1= stepSize / 3 * fc_train[1][:,1:3,0]+stepSize*k2y1/2\n",
        "    # k4y1= stepSize / 6 * fc_train[1][:,1:3,0]+stepSize*k3y1\n",
        "\n",
        "    # k1y2= stepSize / 6 *fc_train[1][:,6:8,0]\n",
        "    # k2y2= stepSize / 3 * fc_train[1][:,6:8,0]+stepSize*k1y2/2\n",
        "    # k3y2= stepSize / 3 * fc_train[1][:,6:8,0]+stepSize*k2y2/2\n",
        "    # k4y2= stepSize / 6 * fc_train[1][:,6:8,0]+stepSize*k3y2\n",
        "\n",
        "    # k1z1= stepSize / 6 * fc_train[1][:,3:5,0]\n",
        "    # k2z1= stepSize / 3 * fc_train[1][:,3:5,0]+ stepSize*k1z1/2\n",
        "    # k3z1= stepSize / 3 * fc_train[1][:,3:5,0]+stepSize*k2z1/2\n",
        "    # k4z1= stepSize / 6 * fc_train[1][:,3:5,0]+stepSize*k3z1\n",
        "\n",
        "    # k1z2= stepSize / 6 * fc_train[1][:,8:10,0]\n",
        "    # k2z2= stepSize / 3 * fc_train[1][:,8:10,0]+stepSize*k1z2/2\n",
        "    # k3z2= stepSize / 3 * fc_train[1][:,8:10,0]+stepSize*k2z2/2\n",
        "    # k4z2= stepSize / 6 * fc_train[1][:,8:10,0]+stepSize*k3z2\n",
        "\n",
        "    # y1 = stepSize*(k1z1+k2z1+k3z1+k4z1)  + x_train[:,1:3] \n",
        "    # z1 = -1 *stepSize*(k1y1+k2y1+k3y1+k4y1)  + x_train[:,3:5] \n",
        "    # y2 = stepSize*(k1z2+k2z2+k3z2+k4z2)   + x_train[:,6:8] \n",
        "    # z2 = -1 * stepSize*(k1y2+k2y2+k3y2+k4y2)  + x_train[:,8:10]\n",
        "\n",
        "\n",
        "    ytrain = stepRK4(f, x_train)\n",
        "    loss_train = mse_loss(ytrain,y_train)\n",
        "\n",
        "    #validation\n",
        "    # fc_val= f(x_val,do_gradient=True,do_hessian = False)\n",
        "\n",
        "    # k1y1= stepSize / 6 * fc_val[1][:,1:3,0]\n",
        "    # k2y1= stepSize / 3 * fc_val[1][:,1:3,0]+stepSize*k1y1/2\n",
        "    # k3y1= stepSize / 3 * fc_val[1][:,1:3,0]+stepSize*k2y1/2\n",
        "    # k4y1= stepSize / 6 * fc_val[1][:,1:3,0]+stepSize*k3y1\n",
        "\n",
        "    # k1y2= stepSize / 6 *fc_val[1][:,6:8,0]\n",
        "    # k2y2= stepSize / 3 * fc_val[1][:,6:8,0]+stepSize*k1y2/2\n",
        "    # k3y2= stepSize / 3 * fc_val[1][:,6:8,0]+stepSize*k2y2/2\n",
        "    # k4y2= stepSize / 6 * fc_val[1][:,6:8,0]+stepSize*k3y2\n",
        "\n",
        "    # k1z1= stepSize / 6 * fc_val[1][:,3:5,0]\n",
        "    # k2z1= stepSize / 3 * fc_val[1][:,3:5,0]+ stepSize*k1z1/2\n",
        "    # k3z1= stepSize / 3 * fc_val[1][:,3:5,0]+stepSize*k2z1/2\n",
        "    # k4z1= stepSize / 6 * fc_val[1][:,3:5,0]+stepSize*k3z1\n",
        "\n",
        "    # k1z2= stepSize / 6 * fc_val[1][:,8:10,0]\n",
        "    # k2z2= stepSize / 3 * fc_val[1][:,8:10,0]+stepSize*k1z2/2\n",
        "    # k3z2= stepSize / 3 * fc_val[1][:,8:10,0]+stepSize*k2z2/2\n",
        "    # k4z2= stepSize / 6 * fc_val[1][:,8:10,0]+stepSize*k3z2\n",
        "\n",
        "\n",
        "    # y1 = stepSize*(k1z1+k2z1+k3z1+k4z1)  + x_val[:,1:3] \n",
        "    # z1 = -1 *stepSize*(k1y1+k2y1+k3y1+k4y1)  + x_val[:,3:5] \n",
        "    # y2 = stepSize*(k1z2+k2z2+k3z2+k4z2)   + x_val[:,6:8] \n",
        "    # z2 = -1 * stepSize*(k1y2+k2y2+k3y2+k4y2)  + x_val[:,8:10]\n",
        "\n",
        "    \n",
        "    yval = stepRK4(f, x_val)\n",
        "    loss_val = mse_loss(yval,y_val)\n",
        "    t = t1-t0\n",
        "    totaltime = totaltime + t\n",
        "    #for printing:\n",
        "    his_iter = (epoch, t1 - t0) + ('|',) + running_loss + ('|',) + (loss_train.item(),) + ('|',) + (loss_val.item(),)\n",
        "    if epoch % log_interval == 0:\n",
        "      print(printouts_frmt.format(*his_iter))\n",
        "\n",
        "    # store history\n",
        "    idx = [idx for idx, n in enumerate(np.array([x for x in printouts_str if not (x == '|')])) if n == 'loss'][1]\n",
        "    his = np.concatenate((his, np.array([x for x in his_iter if not (x == '|')]).reshape(1, -1)), axis=0)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# overall performance on test data\n",
        "# f_test= f(x_test,do_gradient=True,do_hessian = False)\n",
        "\n",
        "# k1y1= stepSize / 6 * f_test[1][:,1:3,0]\n",
        "# k2y1= stepSize / 3 * f_test[1][:,1:3,0]+stepSize*k1y1/2\n",
        "# k3y1= stepSize / 3 * f_test[1][:,1:3,0]+stepSize*k2y1/2\n",
        "# k4y1= stepSize / 6 * f_test[1][:,1:3,0]+stepSize*k3y1\n",
        "\n",
        "# k1y2= stepSize / 6 *f_test[1][:,6:8,0]\n",
        "# k2y2= stepSize / 3 * f_test[1][:,6:8,0]+stepSize*k1y2/2\n",
        "# k3y2= stepSize / 3 * f_test[1][:,6:8,0]+stepSize*k2y2/2\n",
        "# k4y2= stepSize / 6 * f_test[1][:,6:8,0]+stepSize*k3y2\n",
        "\n",
        "# k1z1= stepSize / 6 * f_test[1][:,3:5,0]\n",
        "# k2z1= stepSize / 3 * f_test[1][:,3:5,0]+ stepSize*k1z1/2\n",
        "# k3z1= stepSize / 3 * f_test[1][:,3:5,0]+stepSize*k2z1/2\n",
        "# k4z1= stepSize / 6 * f_test[1][:,3:5,0]+stepSize*k3z1\n",
        "\n",
        "# k1z2= stepSize / 6 * f_test[1][:,8:10,0]\n",
        "# k2z2= stepSize / 3 * f_test[1][:,8:10,0]+stepSize*k1z2/2\n",
        "# k3z2= stepSize / 3 * f_test[1][:,8:10,0]+stepSize*k2z2/2\n",
        "# k4z2= stepSize / 6 * f_test[1][:,8:10,0]+stepSize*k3z2\n",
        "\n",
        "\n",
        "# y1 = stepSize*(k1z1+k2z1+k3z1+k4z1)  + x_test[:,1:3] \n",
        "# z1 = -1 *stepSize*(k1y1+k2y1+k3y1+k4y1)  + x_test[:,3:5] \n",
        "# y2 = stepSize*(k1z2+k2z2+k3z2+k4z2)   + x_test[:,6:8] \n",
        "# z2 = -1 * stepSize*(k1y2+k2y2+k3y2+k4y2)  + x_test[:,8:10]\n",
        "\n",
        "ytest = stepRK4(f,x_test)\n",
        "loss_test = mse_loss(ytest,y_test)\n",
        "print('Test Loss: %0.4e' % loss_test.item())\n",
        "print('Time:' + str(totaltime))\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "#For Convergence Plot:\n",
        "\n",
        "fs=15; tpad=6; lw=3; ms=30\n",
        "\n",
        "rc('axes', linewidth=2)\n",
        "fig = plt.figure()\n",
        "idx = [idx for idx, n in enumerate(np.array([x for x in printouts_str if not (x == '|')])) if n == 'loss'][1]\n",
        "\n",
        "plt.semilogy(his[1::, 0], his[1::, idx], linewidth=lw)\n",
        "\n",
        "plt.xlabel('epoch', fontsize=12)\n",
        "plt.ylabel('loss', fontsize=12)\n",
        "plt.title('Training Loss', fontsize=fs) \n",
        "ax = gca()\n",
        "#plt.legend()\n",
        "\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "for tick in ax.yaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "\n",
        "plt.show()\n",
        "fig.savefig('conv_plot.png',dpi=600, bbox_inches = 'tight', pad_inches = 0.05) #to save the image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i0BF4Ci9x0A"
      },
      "outputs": [],
      "source": [
        "# Go back and solve the ODE, put info in sol array\n",
        "\n",
        "xinit = x_train[0:1,:]\n",
        "steps = 4001\n",
        "h = stepSize\n",
        "sol = torch.zeros(steps,8) #initialize\n",
        "t_solspan = np.zeros(steps) #initialize\n",
        "t=0\n",
        "\n",
        "for i in range(steps): #for each step\n",
        "  # fb = f(xinit,do_gradient=True,do_hessian = False) #plug x_init\n",
        "\n",
        "  # y1 = stepSize*fb[1][:,3:5,0]  + xinit[:,1:3] \n",
        "  # z1 = -1 * stepSize*fb[1][:,1:3,0] + xinit[:,3:5] \n",
        "  # y2 = stepSize*fb[1][:,8:10,0]  + xinit[:,6:8] \n",
        "  # z2 = -1 * stepSize*fb[1][:,6:8,0] + xinit[:,8:10]\n",
        "  yinit = stepRK4(f, xinit)\n",
        "  # print(yinit.shape)\n",
        "  t = t + h\n",
        "  t_solspan[i] = t\n",
        "  xinit = torch.cat((xinit[0:1,0:1] + h, yinit[0:1,0:4], xinit[0:1,5:6] + h, yinit[0:1,4:8]),dim=1)\n",
        "  sol[i:i+1,:] = yinit #store in solutions\n",
        "# t_solspan[1] = t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRQQDnIFADoS"
      },
      "outputs": [],
      "source": [
        "sol = sol.t().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHjrxvMSBnoM"
      },
      "outputs": [],
      "source": [
        "orbit_sol = np.ones((2,5,steps))\n",
        "orbit_sol[0,1:5,:] = sol[:4,:]\n",
        "orbit_sol[1,1:5,:] = sol[4:8,:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orbit_sol.shape"
      ],
      "metadata": {
        "id": "kfvzF_i-l-8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are plotting our learned positions against the true positions\n",
        "\n",
        "fs=15; tpad=6; lw=3; ms=30\n",
        "\n",
        "plt.title('Learned Position Values', fontsize=fs)\n",
        "\n",
        "#lines\n",
        "plt.plot(t_solspan,orbit_sol[0][1,:], \"k-\",linewidth=lw,  color = \"orange\", label='Learned Body 1 Position'.format(i))\n",
        "plt.plot(t_solspan,orbit_sol[1][1,:], \"k-\", linewidth=lw, color = \"royalblue\", label='Learned Body 2 Position'.format(i))\n",
        "\n",
        "holder = 0\n",
        "\n",
        "plt.plot(settings['t_eval'][:steps],orbit[0][1,:steps], \"k-.\", label='True Values')\n",
        "plt.plot(settings['t_eval'][:steps],orbit[1][1,:steps], \"k-.\")\n",
        "\n",
        "#labels\n",
        "plt.xlabel('Time', fontsize=12) \n",
        "plt.ylabel('px', fontsize=12)\n",
        "plt.legend(fontsize=7, loc='lower right', prop={'size':10})\n",
        "\n",
        "ax = gca()\n",
        "\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "for tick in ax.yaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "\n",
        "plt.savefig('learned position.png',dpi=600, bbox_inches = 'tight', pad_inches = 0.05) "
      ],
      "metadata": {
        "id": "5cvRxsKWfhpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YpZVq4-u33P"
      },
      "outputs": [],
      "source": [
        "#Plot the predicted Trajectories of our bodies\n",
        "fs=15; tpad=6; lw=3; ms=30\n",
        "rc('axes', linewidth=2)\n",
        "\n",
        "plt.title('Trajectories', fontsize=fs, pad=tpad)\n",
        "colors = [\"orange\", \"royalblue\"]\n",
        "labels = [\"Body 1\", \"Body 2\"]\n",
        "plt.xlabel('px', fontsize=12) \n",
        "plt.ylabel('qx', fontsize=12)\n",
        "\n",
        "\n",
        "ax = gca()\n",
        "\n",
        "for i, path in enumerate(orbit_sol):\n",
        "    plt.plot(path[1], path[2], \"k-\", linewidth=lw, color = colors[i], label=labels[i].format(i))\n",
        "for i, path in enumerate(orbit):\n",
        "    plt.plot(path[1], path[2], \"k:\", linewidth=lw, label='ground truth'.format(i))\n",
        "plt.legend(fontsize=7, loc='lower right', prop={'size':10})\n",
        "\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "for tick in ax.yaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "\n",
        "plt.savefig('Trajectories.png',dpi=600, bbox_inches = 'tight', pad_inches = 0.05) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the energy values\n",
        "\n",
        "\n",
        "tail=10000; pfrac=0.05\n",
        "\n",
        "\n",
        "k = 4001\n",
        "\n",
        "\n",
        "tstart = max(0, k-tail)\n",
        "\n",
        "real_pe = potential_energy(orbit_sol[...,tstart:k])\n",
        "real_ke = kinetic_energy(orbit_sol[...,tstart:k])\n",
        "real_etot = total_energy(orbit_sol[...,tstart:k])\n",
        "ymin = np.min([real_pe.min(), real_ke.min(), real_etot.min()])\n",
        "ymax = np.max([real_pe.max(), real_ke.max(), real_etot.max()])\n",
        "pad = (ymax-ymin)*pfrac\n",
        "ymin -= pad\n",
        "ymax += pad\n",
        "rc('axes', linewidth=2)\n",
        "\n",
        "#lines\n",
        "plt.plot(settings['t_eval'], real_ke,'k--', linewidth=lw, label='Kinetic')\n",
        "plt.plot(settings['t_eval'], real_pe,'k:', linewidth=lw, label='Potential')\n",
        "plt.plot(settings['t_eval'], real_etot,'k-.', linewidth=lw, label='Total')\n",
        "plt.plot(settings['t_eval'], potential_energy(orbit), label='potential', color = 'purple')\n",
        "plt.plot(settings['t_eval'], kinetic_energy(orbit), label='kinetic')\n",
        "plt.plot(settings['t_eval'], total_energy(orbit), label='total', color = \"red\")\n",
        "\n",
        "ax = gca()\n",
        "\n",
        "#labels\n",
        "plt.title('Energy', fontsize=fs, pad=tpad)\n",
        "plt.xlabel('Time', fontsize=12) \n",
        "plt.ylabel(\"Energy\", fontsize=12)\n",
        "plt.ylim(ymin, ymax)\n",
        "plt.legend(fontsize=7, loc='best', prop={'size':10})\n",
        "\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "for tick in ax.yaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "\n",
        "# plt.savefig('Energy.png',dpi=600, bbox_inches = 'tight', pad_inches = 0.05) "
      ],
      "metadata": {
        "id": "zILVrkVqI9VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdzikPobCtUC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "All Four Figures in One Rectangle\n",
        "  - Edit the sizing for scaling, and add or remove whitspace with pad_inches\n",
        "\n",
        "'''\n",
        "\n",
        "fs=15; tpad=6; lw=3; ms=30\n",
        "\n",
        "\n",
        "# convergence plot\n",
        "rc('axes', linewidth=2)\n",
        "fig = plt.figure(figsize=(18, 12))\n",
        "plt.subplot(2, 2, 1)\n",
        "idx = [idx for idx, n in enumerate(np.array([x for x in printouts_str if not (x == '|')])) if n == 'loss'][1]\n",
        "\n",
        "plt.semilogy(his[1::, 0], his[1::, idx], linewidth=lw)\n",
        "\n",
        "#labels\n",
        "plt.xlabel('epoch', fontsize=12)\n",
        "plt.ylabel('loss', fontsize=12)\n",
        "plt.title('Training Loss', fontsize=fs) \n",
        "\n",
        "ax = gca()\n",
        "\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "for tick in ax.yaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "\n",
        "\n",
        "\n",
        "#Plot the trajectories\n",
        "\n",
        "rc('axes', linewidth=2)\n",
        "\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.title('Trajectories', fontsize=fs, pad=tpad)\n",
        "colors = [\"red\", \"royalblue\"]\n",
        "labels = [\"Body 1\", \"Body 2\"]\n",
        "plt.xlabel('px', fontsize=12) \n",
        "plt.ylabel('qx', fontsize=12)\n",
        "\n",
        "\n",
        "\n",
        "ax = gca()\n",
        "\n",
        "for i, path in enumerate(orbit_sol):\n",
        "    plt.plot(path[1], path[2], \"k-\", linewidth=lw, color = colors[i], label=labels[i].format(i))\n",
        "for i, path in enumerate(orbit):\n",
        "    plt.plot(path[1], path[2], \"k:\", linewidth=lw, label='ground truth'.format(i))\n",
        "plt.legend(fontsize=7, loc='lower right', prop={'size':12})\n",
        "\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "for tick in ax.yaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "\n",
        "\n",
        "#Plot the energy values\n",
        "\n",
        "tail=10000; pfrac=0.05\n",
        "\n",
        "\n",
        "k = 4001\n",
        "\n",
        "\n",
        "tstart = max(0, k-tail)\n",
        "\n",
        "real_pe = potential_energy(orbit_sol[...,tstart:k])\n",
        "real_ke = kinetic_energy(orbit_sol[...,tstart:k])\n",
        "real_etot = total_energy(orbit_sol[...,tstart:k])\n",
        "ymin = np.min([real_pe.min(), real_ke.min(), real_etot.min()])\n",
        "ymax = np.max([real_pe.max(), real_ke.max(), real_etot.max()])\n",
        "pad = (ymax-ymin)*pfrac\n",
        "ymin -= pad\n",
        "ymax += pad\n",
        "\n",
        "\n",
        "rc('axes', linewidth=2)\n",
        "\n",
        "#lines\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.title('Energy', fontsize=fs, pad=tpad)\n",
        "plt.plot(settings['t_eval'], real_ke,'k--', linewidth=lw, label='Kinetic')\n",
        "plt.plot(settings['t_eval'], real_pe,'k:', linewidth=lw, label='Potential')\n",
        "plt.plot(settings['t_eval'], real_etot,'k-.', linewidth=lw, label='Total')\n",
        "plt.plot(settings['t_eval'], potential_energy(orbit), label='potential', color = 'purple')\n",
        "plt.plot(settings['t_eval'], kinetic_energy(orbit), label='kinetic')\n",
        "plt.plot(settings['t_eval'], total_energy(orbit), label='total', color = \"red\")\n",
        "\n",
        "ax = gca()\n",
        "\n",
        "#labels\n",
        "plt.xlabel('Time', fontsize=12) \n",
        "plt.ylabel(\"Energy\", fontsize=12)\n",
        "plt.ylim(ymin, ymax)\n",
        "plt.legend(fontsize=7, loc='best', prop={'size':12})\n",
        "\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "for tick in ax.yaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "\n",
        "\n",
        "\n",
        "#Plot the learned vs ground positions\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "\n",
        "#lines\n",
        "plt.plot(t_solspan,orbit_sol[0][1,:], \"k-\",linewidth=lw,  color = \"orange\", label='Learned Body 1 Position'.format(i))\n",
        "plt.plot(t_solspan,orbit_sol[1][1,:], \"k-\", linewidth=lw, color = \"royalblue\", label='Learned Body 2 Position'.format(i))\n",
        "\n",
        "holder = 0\n",
        "\n",
        "ax = gca()\n",
        "\n",
        "plt.plot(settings['t_eval'][:steps],orbit[0][1,:steps], \"k-.\", label='True Values')\n",
        "plt.plot(settings['t_eval'][:steps],orbit[1][1,:steps], \"k-.\")\n",
        "\n",
        "#labels\n",
        "plt.title('Learned Position Values', fontsize=fs)\n",
        "plt.xlabel('Time', fontsize=12) \n",
        "plt.ylabel('px', fontsize=12)\n",
        "plt.legend(fontsize=7, loc='lower right', prop={'size':12})\n",
        "\n",
        "for tick in ax.xaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "for tick in ax.yaxis.get_major_ticks():\n",
        "    tick.label1.set_fontsize(12)\n",
        "\n",
        "fig.savefig('2 Body Combo.png',dpi=600, bbox_inches = 'tight', pad_inches = 0.05) \n",
        "#tikzplotlib.save('energy.tex')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}